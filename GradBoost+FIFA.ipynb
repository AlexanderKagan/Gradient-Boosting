{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собственный класс градиентного бустинга и его применение на датасете игроков FIFA Ultimate Team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Реализация градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с функций потерь. Нам нужны будут две функции потерь, одна для задачи классификации и одна для задачи регрессии. Для каждой из них напишем отдельный класс, который позволит вычислять как саму функцию потерь, так и ее градиент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Базовый класс Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала напишем базовый класс `Loss`, от которого будем наследоваться при написании функций потерь.\n",
    "Вычисление значения функции потерь будет производиться в методе `forward`, а градиента - в методе `backward`.\n",
    "\n",
    "Метод `forward` должен получать на вход два вектора: вектор целевых переменных и вектор предсказаний модели.\n",
    "Метод должен: \n",
    "* проверять, что длины векторов совпадают (с помощью `assert`)\n",
    "* возвращать вектор той же длины, содержащий значения функции потерь для каждого из объектов\n",
    "\n",
    "Метод `grad` должен делать то же самое, но возвращать значение градиента функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "    \n",
    "    def __call__(self, y, p):\n",
    "        \"\"\"\n",
    "        Call and use .forward()\n",
    "        :param y: array-like targets\n",
    "        :param p: array-like predictions\n",
    "        :return array-like loss values\n",
    "        \"\"\"\n",
    "        return self.forward(y, p)\n",
    "        \n",
    "    def forward(self, y, p):\n",
    "        \"\"\"\n",
    "        Calculate loss value\n",
    "        :param y: array-like targets\n",
    "        :param p: array-like predictions\n",
    "        :return array-like loss values\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def grad(self, y, p):\n",
    "        \"\"\"\n",
    "        Calculate grad value\n",
    "        :param y: array-like targets\n",
    "        :param p: array-like predictions\n",
    "        :return array-like grad values\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Функция потерь для задачи регрессии (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи регрессии будем использовать `Mean Squared Error (MSE)`:\n",
    "\n",
    "$$L = MSE(y,p) = \\frac{1}{2n}(y - p) ^ 2$$\n",
    "\n",
    "Ее градиент:\n",
    "$$\\frac{\\partial L}{\\partial p} = \\frac{1}{n}(p - y)$$\n",
    "\n",
    "В формулах выше `p` - предсказания модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MSELoss(Loss):\n",
    "    \n",
    "    def forward(self, y, p):\n",
    "        assert len(y) == len (p), '%s is not the same length as %s'% (y, p)\n",
    "        return 0.5 / len(y) * (y - p) ** 2\n",
    "    \n",
    "    def grad(self, y, p):\n",
    "        assert len(y) == len (p), '%s is not the same length as %s'% (y, p)\n",
    "        return (p - y) #не делю на n, так как ухудшает сходимость!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки корректности своего кода используйте ячейку ниже.\n",
    "\n",
    "*Код в ячейках ниже должен выполняться без ошибок.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_loss = MSELoss()\n",
    "\n",
    "ys = np.array((10, 20, 30))\n",
    "ps = np.array((5, 25, 30))\n",
    "\n",
    "np.testing.assert_raises(AssertionError, mse_loss, np.asarray([1, 2, 3]), np.asarray([1, 2, 3, 4, 5]))\n",
    "np.testing.assert_raises(AssertionError, mse_loss.grad, np.asarray([1, 2, 3]), np.asarray([1, 2, 3, 4, 5]))\n",
    "\n",
    "np.testing.assert_almost_equal(mse_loss(ys, ps), np.asarray([4.16667, 4.1666, 0]), decimal=4)\n",
    "np.testing.assert_almost_equal(mse_loss.grad(ys / len(ys), ps / len(ps)), np.asarray([-1.66667, 1.66667, 0]), decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если ошибок нет, можно переходить к следующей части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Функция потерь для задачи классификации (BCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи регрессии будем использовать `Binary Cross-Entropy (BCE)`:\n",
    "$$L = BCE(y,p) = \\frac{1}{n}(-y \\log{p} - (1-y)\\log{(1-p)})$$\n",
    "\n",
    "Ее градиент по `p`:\n",
    "$$\\frac{\\partial L}{\\partial p} = \\frac{(p - y)}{p(1-p)}$$\n",
    "\n",
    "Вспомним, что для вычисления `p` используется сигмоида:\n",
    "$$p = \\sigma (z) = \\frac{1}{1 + \\exp (-z)}$$\n",
    "$$\\sigma (z)' = \\sigma (z) (1 - \\sigma (z))$$\n",
    "\n",
    "Подставив последнее выражение в градиент функции потерь, получим аналогичное `MSE` выражение:\n",
    "$$\\frac{\\partial L}{\\partial z} = \\frac{1}{n}(z - y)$$\n",
    "\n",
    "В формулах выше `z` - предсказания модели до применения сигмоиды, `p` - после.\n",
    "\n",
    "**Важно:** для дальнейшего удобства методы `forward` и `grad` в качестве предсказаний должны получать `z`, **активации** модели, то есть результат вычислений модели без взятия сигмоиды от них; сигмоидальное преобразования реализуется внутри этих методов (см.код).\n",
    "\n",
    "**Важно:** не забудьте при вычислении логарифмов добавить отсечку значений аргумента значениями (`eps`, 1 - `eps`) в избежание ошибок арифметики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsLoss(Loss):\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, y, z):\n",
    "        eps = 1e-5\n",
    "        p = sigmoid(z)\n",
    "        assert len(y) == len (p), '%s is not the same length as %s'% (y, p)\n",
    "        p[p <= 0] = eps\n",
    "        p[p >= 1] = 1 - eps\n",
    "        return - 1 / len(y) * (y * np.log(p) + (1 - y) * np.log(1-p))\n",
    "    \n",
    "    def grad(self, y, z):\n",
    "        eps = 1e-5\n",
    "        p = sigmoid(z)\n",
    "        assert len(y) == len (p), '%s is not the same length as %s'% (y, p)\n",
    "        p[p <= 0] = eps\n",
    "        p[p >= 1] = 1 - eps\n",
    "        return (p - y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки корректности своего кода используйте ячейку ниже.\n",
    "\n",
    "*Код в ячейках ниже должен выполняться без ошибок.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bce_loss = BCEWithLogitsLoss()\n",
    "\n",
    "ys = np.array((1, 0, 0))\n",
    "zs = np.array((0.0, 100.0, 1.0))\n",
    "\n",
    "np.testing.assert_raises(AssertionError, bce_loss, np.asarray([1, 2, 3]), np.asarray([1, 2, 3, 4, 5]))\n",
    "np.testing.assert_raises(AssertionError, bce_loss.grad, np.asarray([1, 2, 3]), np.asarray([1, 2, 3, 4, 5]))\n",
    "\n",
    "np.testing.assert_array_less(bce_loss(ys, zs), np.inf)\n",
    "\n",
    "np.testing.assert_almost_equal(bce_loss(ys, zs), np.asarray([0.231 , 3.8376, 0.4378]), decimal=4)\n",
    "np.testing.assert_almost_equal(bce_loss.grad(ys, zs), np.asarray([-0.1667,  0.3333,  0.2437]), decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если ошибок нет, можно переходить к следующей части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Класс GradentBoosting\n",
    "После того, как были получены классы для функций потерь, можно приступать к реализации класса для градиентного бустинга `GradientBoosting`.\n",
    "В качестве базовых моделей будем использовать деревья решений (`DecisionTreeRegressor` из `sklearn.tree`).\n",
    "Итоговый вид композиции:\n",
    "$$a(x) = \\sum_{t=1}^{T}\\eta * b_{t}(x)$$\n",
    "\n",
    "Параметры класса (аргументы метода `__init__()`):\n",
    "* `loss`: объект одного из двух классов, реализованных выше (`MSELoss` или `BCELoss`), будет определять поведение при вызове метода `predict()`.\n",
    "* `n_estimators`: число деревьев `T` (итераций бустинга)\n",
    "* `learning_rate`: темп обучения (коэффициент $\\eta$)\n",
    "* `max_depth`: максимальная глубина построенных деревьев (параметр `DecisionTreeRegressor`)\n",
    "* `max_features`: число признаков для поиска наилучшего разбиения в узле (параметр `DecisionTreeRegressor`)\n",
    "\n",
    "В методе `__init__()` создаются списки для хранения отдельных деревьев (`self.estimators`) и значений функции потерь на каждом шаге (`self.loss_values`).\n",
    "Также имеется дополнительное поле `self.loss_values_evalset`, в котором можно хранить значения функции потерь на отложенной (`evalset`) выборке по итерациям.\n",
    "\n",
    "Метод `fit(X, y, X_eval=None, y_eval=None)` должен:\n",
    "* Инициализировать \"нулевое приближение\" средним значением целевой переменной, считать значение потерь при нем\n",
    "* Итерируясь по числу деревьев:\n",
    "  * Вычислять **антиградиент** функции потерь построенной композиции по каждому объекту (остатки), создавать новое дерево, обучать его на полученных остатках и добавлять в список деревьев.\n",
    "  * Вычислять новое значение предсказания композиции для обучающей выборки (добавлением ответов нового дерева с весом $\\eta$)\n",
    "  * Считать новое значение функции потерь (суммарно по всем объектам) и добавлять в список\n",
    "* В случае, если методу передаются также `X_eval` и `y_eval`, нужно вычислять значение функции потерь на этом множестве на каждой итерации.\n",
    "  \n",
    "Метод `predict(X)` должен:\n",
    "* Для каждого объекта из `X` делать предсказание с помощью всех деревьев композиции  (**не забывайте про \"нулевое приближение\"**) и суммировать их\n",
    "* Если решается задача классификации, применять сигмоиду на полученных ответах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GradientBoosting(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 loss=None,\n",
    "                 n_estimators=10, \n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=3,\n",
    "                 max_features='auto',\n",
    "                 random_state=2):\n",
    "        self.loss = loss\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        \n",
    "        self.estimators = []\n",
    "        self.loss_values = []\n",
    "        self.loss_values_evalset = []\n",
    "        \n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_evalset=[], y_evalset=[], verbose=False, patience=3, decrease_treshold=0.001): \n",
    "        iter_prediction = np.array([y_train.mean() for i in range (len(y_train))])\n",
    "        iter_loss = self.loss.forward(y_train, iter_prediction)\n",
    "        self.loss_values.append(iter_loss.sum())\n",
    "        self.estimators.append(iter_prediction)\n",
    "        if len(y_evalset) != 0:\n",
    "            iter_prediction_eval = np.array([y_evalset.mean() for i in range (len(y_evalset))])\n",
    "        for t in range(1, self.n_estimators):\n",
    "            antigradient = - self.loss.grad(y_train, iter_prediction)\n",
    "            tree = DecisionTreeRegressor (max_depth=self.max_depth, \\\n",
    "                                          max_features=self.max_features, \\\n",
    "                                          random_state=self.random_state). \\\n",
    "                                        fit(X_train, antigradient)\n",
    "            self.estimators.append(tree)\n",
    "            iter_prediction += self.learning_rate * tree.predict(X_train)\n",
    "            iter_loss = self.loss.forward(y_train, iter_prediction)\n",
    "            self.loss_values.append(iter_loss.sum())\n",
    "            if verbose == True and t % 10 == 0:\n",
    "                print ('Iter # %s:' %t, 'Loss value: %s' %self.loss_values[-1])\n",
    "            if len(y_evalset) != 0:\n",
    "                iter_prediction_eval += tree.predict(X_evalset)\n",
    "                iter_loss_eval = self.loss.forward(y_evalset, iter_prediction_eval)\n",
    "                self.loss_values_evalset.append(iter_loss_eval.sum())\n",
    "                if t % 10 == 0 and verbose == True:\n",
    "                    print('Loss on evalset: %s' %self.loss_values_evalset[-1])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #prediction = self.estimators[0][:X.shape[0]]\n",
    "        prediction = np.zeros(X.shape[0])\n",
    "        for tree in self.estimators[1:]:\n",
    "            prediction += self.learning_rate * tree.predict(X)\n",
    "        return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Тестирование класса GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1. Интерфейс\n",
    "*Код в ячейках ниже должен выполняться без ошибок.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.random.uniform(size=(100, 2))\n",
    "y_test = np.random.uniform(size=100)\n",
    "\n",
    "gb_test = GradientBoosting(loss=MSELoss(), n_estimators=100)\n",
    "gb_test.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(gb_test.estimators) == gb_test.n_estimators\n",
    "assert gb_test.predict(X_test).shape == y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем случайную выборку и убедимся, что функция потерь уменьшается при увеличении итераций.\n",
    "\n",
    "*Код в ячейках ниже должен выполняться без ошибок.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2. Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD0CAYAAAB+WlaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4cIk5IUQwoVJyAshhAv7/2HaQiYZZHX/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = np.random.uniform(size=(100, 2))\n",
    "y_test = np.random.uniform(size=100)\n",
    "\n",
    "gb_test = GradientBoosting(loss=MSELoss(), n_estimators=100)\n",
    "gb_test.fit(X_test, y_test)\n",
    "\n",
    "loss_values = gb_test.loss_values\n",
    "plt.plot(loss_values)\n",
    "np.testing.assert_array_equal(loss_values, sorted(loss_values, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD0CAYAAAB+WlaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XlU1PX+x/HnDJsKiuGCiEuCGy6o\nqJkLYCmKtphbKIXdbNHcUqxrai75M7VNFFzSutKNFi3atERcKlBcElITQ00lLcUtFQVlc+b3hze6\nXi0SgYGZ1+Mcz2G+y3zf70O9+JyZ7/fzMZjNZjMiImKVjJYuQERESo9CXkTEiinkRUSsmEJeRMSK\nKeRFRKyYQl5ExIrZW7qA/5WSkmLpEkREKqT27dvfsK3chTzcvNC/Iy0tDR8fnxKupnyzxZ7BNvu2\nxZ7BNvsuTs9/NkDWxzUiIlZMIS8iYsUU8iIiVkwhLyJixRTyIiJWTCEvImLFFPIiIlbMakL++Y/3\n8EL8CdLPZlu6FBGRcsNqQr53yzocPpdH8IJE3t58hKsmrYUiIlJkyJtMJqZPn05ISAhhYWEcPXq0\ncF9aWhphYWGF/1q3bk1iYmLh/p07dxIYGFj4+ocffiA0NJShQ4cybtw4cnNzS6yRni3cebNfPbo1\nrsnsr9IIWbaNI2eySuz9RUQqoiKnNdi4cSN5eXmsWrWK3bt3M2/ePJYuXQqAj48PMTExAMTFxVG7\ndm0CAgIAyMjIYMWKFRQUFABgNpuZNm0akZGRNGzYkI8//pjjx4/j5eVVYs3UqGLP24914LNdx5m5\neh99Fm7m+d7NeLxrI+yMhhK7johIRVHkSD4lJQV/f38A2rZtS2pq6g3HXL58maioKKZOnQpAbm4u\nM2bMYObMmYXHpKenU716df7973/z6KOPcuHChRIN+N8ZDAYG+NVjY3gg/k2ujeoHv7mVwxrVi4gN\nKnIkn5WVhYuLS+FrOzs7CgoKsLf/49TY2FiCg4Nxc3MDYNasWQwfPhx3d/fCY86fP8+uXbuYNm0a\nDRs2ZOTIkbRq1YrOnTvfcM20tLRiNZOTk3PdueEdnWlXoxZLv/uN4IhEhrW7g/4tXK1qVP+/PdsK\nW+zbFnsG2+y7JHsuMuRdXFzIzv7jjhWTyXRdwAOsWbOGyMhIAE6dOkVycjLHjh1j8eLFZGZmMmHC\nBMaMGUPDhg1p3LgxAP7+/qSmpt405Is749zNZm5r0QIGB+bw4mep/CvlFCmnTbw+2JfGtasW6xrl\njS3O0Ae22bct9gy22XeZzkLp5+dX+GXq7t27adq06XX7L126RF5eHh4eHgC4u7sTHx9PTEwMMTEx\nuLq6EhERQf369cnOzi784jY5OZkmTZrcUhPFVbtqJZaFtWfhkLYc/S2bvpFbeDPhMAVXTWVyfRER\nSylyJB8UFERSUhJDhgzBbDYzZ84coqOjadCgAT169CA9PR1PT88iL+To6MjLL7/MxIkTMZvNtGvX\nju7du5dED3+LwWCgX1tPunjXZNrnqcyL209c6kleH+RLE3frGNWLiPyvIkPeaDQya9as67Z5e3sX\n/uzr68uSJUv+9PykpKTCnzt37kxsbGxx6iwxtao6sfRRP778IYPpX6RyX+QWnu3ZhBEBXtjbWc1j\nAyIigBU9DHUrDAYDD7Spy4bwQHq2qM1r8QcYsHQrB05esnRpIiIlyiZD/nc1XZxY8kh7Fof6cfz8\nFe6P2syir38iX5/Vi4iVsOmQ/919vh6snxBA75Z1eH39QfovSSIt46KlyxIRuW0K+f+o4eLEolA/\n3nzUj5OZOTy4aAsLN2pULyIVm0L+fwS38mD9hED6tvYgYuNB+i1KYt+JTEuXJSJSLAr5m3BzdmTh\nkHYsC2vP6Uu59FuUxPwNB8kr0KheRCoWhfxf6N2yDhvDA3igTV0iN/3Eg4u2sPdXjepFpOJQyBeh\nehVHIkLa8q/HOnAuO4+HliTxWvx+cguuWro0EZEiKeT/ph4+7myYEEj/dp4s/uYwD0RtYc8vFyxd\nlojIX1LI3wLXKg68PrgN0Y935OKVAvovSWJe3H5y8jWqF5HySSFfDPc0q8368AAGt6/PmwmHuS9y\nM98fO2/pskREbqCQL6ZqlRx4ZZAv7w6/iyt5Vxm0dCsvf/WjRvUiUq4o5G9TQNNaxE8IYMhdDXhr\nczp9Fm4m+edzli5LRARQyJeIqpUcmNO/NR882Yn8qyYGL9vGrDU/ciVPo3oRsSyFfAnq0rgm8eMD\nGHZ3Q1YkpRO8MJEdR36zdFkiYsMU8iXM2cmel/q1YuXTdwMQsnw7M75IJTu3wMKViYgtUsiXkru9\nahD3rD/Duzbi3e1H6b0gka2Hzlq6LBGxMQr5UlTF0Z7pD7Tg4xGdcbQzEvr2DqZ8tpdLOfmWLk1E\nbIRCvgx0uNONtc/683SAFyu/O0bviEQSD56xdFkiYgMU8mWkkoMdU/r68MkzXajiZM+wFd/xz9g9\nZF7RqF5ESo9Cvoy1a3AHX47txjPdvfnk++P0ikhgU9opS5clIlZKIW8BlRzsmBTcnM9GdaF6ZUee\n+Hcy4at2c+FynqVLExEro5C3IN961Vk9tivjejRh9Z4TBEUkEr/vpKXLEhEropC3MCd7O8KDmvLF\nmK7UcnFiREwKYz/cxblsjepF5PYp5MuJlnVd+WJMVyYGNWVdagZB8xP46ocMS5clIhWcQr4ccbAz\nMrZHE9aM7YbnHZUZ/cH3PPNeCmcu5Vq6NBGpoBTy5VDzOtX49JkuTApuzqb9pwmKSODzXccxm82W\nLk1EKhiFfDllb2fkme7erB3XjUY1nRm/ajdPvZvMqYs5li5NRCoQhXw517h2VWJHduHF+3zY/NNZ\nes5P4KPkXzSqF5G/RSFfAdgZDTzp78W68QH41KnGP2N/4B/ROzl+4YqlSxORck4hX4E0qunMyqfv\n5qUHW7Lz53P0jkhk7YGLGtWLyJ9SyFcwRqOBx7rcSfz4AHzruRK1/SyPvL2DX85dtnRpIlIOKeQr\nqPpuVXj/yU6M7VyTH37NpFdEIu8kpWMyaVQvIn9QyFdgBoOBvk2rsX5CAHc1cmPmmh8Zsnw76Wez\nLV2aiJQTCnkrULd6Zd55vCOvD27D/pMXCV6QyFuJR7iqUb2IzVPIWwmDwcCg9vXYEB6If5NavLw2\njYFLt/LTqUuWLk1ELEghb2Xcq1XirWHtWTikLUd/y+a+yC0s+von8q+aLF2aiFiAQt4KGQwG+rX1\nZEN4IEEt3Xl9/UEeWpzEvhOZli5NRMqYQt6K1XRxYnGoH28+6sepi7n0W5TE/PUHyCvQqF7EVijk\nbUBwKw82TAjgwTZ1ifz6EA9EbWHPLxcsXZaIlIEiQ95kMjF9+nRCQkIICwvj6NGjhfvS0tIICwsr\n/Ne6dWsSExML9+/cuZPAwMAb3nPatGm8/vrrJdSC/B13ODsyP6Qt/3qsAxeu5NF/SRJz49LIyb9q\n6dJEpBTZF3XAxo0bycvLY9WqVezevZt58+axdOlSAHx8fIiJiQEgLi6O2rVrExAQAEBGRgYrVqyg\noKDguvdbuXIlBw8epGPHjiXdi/wNPXzcWX+nG3PXprEs4QgbfjzFqwN96XCnm6VLE5FSUORIPiUl\nBX9/fwDatm1LamrqDcdcvnyZqKgopk6dCkBubi4zZsxg5syZ1x23a9cu9uzZQ0hISAmULsXlWtmB\neQN9iXniLnLzTQxeto2X1uzjcl5B0SeLSIVS5Eg+KysLFxeXwtd2dnYUFBRgb//HqbGxsQQHB+Pm\ndm00OGvWLIYPH467u3vhMadPn2bRokUsWrSIuLi4v7xmWlraLTcCkJOTU+xzK6rb6bkmENXXneiU\nc0Qn/Uzcnl8Z36UWbTwql2yRpUC/a9thi32XZM9FhryLiwvZ2X88Jm8yma4LeIA1a9YQGRkJwKlT\np0hOTubYsWMsXryYzMxMJkyYQLt27Th//jxPP/00Z86cIScnBy8vLwYMGHDDNX18fIrVTFpaWrHP\nrahKomc/X3j0yG9M+uQHXlifQWinBkzu05yqlRxKqMqSp9+17bDFvovTc0pKyk23Fxnyfn5+fPPN\nN/Tt25fdu3fTtGnT6/ZfunSJvLw8PDw8AHB3dyc+Pr5wf9euXYmIiABg2LBhAHz66accOXLkpgEv\nltHJqwZxzwYwf8MB/rUlnW/3n2bOgNZ0b1bb0qWJyG0o8jP5oKAgHB0dGTJkCHPnzmXy5MlER0ez\nadMmANLT0/H09Cz1QqX0VXa0Y+p9LYh9pgtVnOz5R/ROJn60hwuX8yxdmogUU5EjeaPRyKxZs67b\n5u3tXfizr68vS5Ys+dPzk5KSbtimEXz55tfgDr4a142oTYdYmnCYxJ/OMPuhVvRuWcfSpYnILdLD\nUHJTTvZ2PNe7GV+M7kpNFydGxKQw9sNd/JaVa+nSROQWKOTlL7XydGX1mK5MDGrKutQMgiISWbPn\nhJYcFKkgFPJSJAc7I2N7NOHLsf7Uv6MyYz/cxdMxKZy+mGPp0kSkCAp5+dua1anKJ890YUrf5iQe\nPEPP+Ql8nPyLRvUi5ZhCXm6JvZ2RpwO8iXvWn2Z1qvJ87A88Fr2TX89rIXGR8kghL8XiVcuFVU93\n5qUHW5L88zl6RyQSs/2oFhIXKWcU8lJsRqOBx7rcSfz4ANo1uINpn6cy9K3t/KyFxEXKDYW83Lb6\nblWIeeIuXhnYmh8zLhK8MJG3N2shcZHyQCEvJcJgMBDSsQEbJgTSrXFNZn91bSHxg1pIXMSiFPJS\nouq4VuKtYR0KFxK/P3ILUZu0kLiIpSjkpcT990LivVq688aGg/RblETqcS0kLlLWFPJSamq6OLEo\n1I83H23P6Uu59FucxGvx+7XkoEgZUshLqQtuVYeN4QE81NaTxd8c5v6oLXx/7LylyxKxCQp5KRPV\nqzjyxsNteOfxjlzOLWDg0q3MWvOjlhwUKWUKeSlT3ZvVZn14II90asCKpHSCF2xm6+Gzli5LxGop\n5KXMuTjZM/uh1qx8+m6MBgh9aweTP93LxZx8S5cmYnUU8mIxd/9nycGn/Buxaucxes1P5Ov9pyxd\nlohVUciLRf2+5OCno7pSrbI9w99JZsKq3ZzP1pKDIiVBIS/lQtv61VkzthvjejRhzZ4TBEUksHZv\nhqXLEqnwFPJSbjjZ2xEe1JTVY7rh4VqZUe9/z8iYFE5f0uIkIsWlkJdyp0Xdanw2qguTgpvz9YHT\nBM1PJDblVy1OIlIMCnkpl+ztjDzT/driJE1qu/Dcx3v4R/ROjl+4YunSRCoUhbyUa961XPhoxLXF\nSXb+fI5e8xOI2fYzJo3qRf4WhbyUezcsTvLFPibFZ5CuxUlEiqSQlwrj98VJXh3oS/q5PIIXJLIs\n4TAFmsZY5E8p5KVCMRgMPNyxPsseqkdA01rMjdvPgKVb2X/yoqVLEymXFPJSIdWoYs/ysPZEDW3H\n8fNXuD9yC/M3HCSvQKN6kf+mkJcKy2Aw8ECbumwID+R+Xw8iN/3E/VGb2f3LBUuXJlJuKOSlwnNz\ndmTBkHb867EOXLxSwIAlSbz81Y9cydPiJCIKebEaPXzcWR8eQEjHBry1OZ3ghYlsP/KbpcsSsSiF\nvFiVapUcmDugNR881QmzGYYs387Uz/ZySdMYi41SyItV6uJdk/jxATzZrREffneMXhGJfLP/tKXL\nEilzCnmxWpUd7Xjx/hZ88kwXXJzsefydnUxYtZtzmsZYbIhCXqxeuwZ38OW4boy7t/G1aYznJ/Dl\nDyc04ZnYBIW82AQnezvCezVjzdhu1K1emTEf7GJETAqnLmoaY7FuCnmxKT4e16YxntynOQkHz9Bz\nfgKrdh7TqF6slkJebI69nZERgd6sGx+Aj0c1Jn2yl7B/fccv5y5bujSREqeQF5vVqKYzK5+6m/97\nqBW7jp2nV0QiK7akc9WkUb1YD4W82DSj0UDY3Q1ZHx5IJy83Zn35I4Pf3Mqh05csXZpIiVDIiwCe\n1SsT/Y+ORIS04cjZbPou3ELUpp/I1zTGUsEVGfImk4np06cTEhJCWFgYR48eLdyXlpZGWFhY4b/W\nrVuTmJhYuH/nzp0EBgYWvv7yyy8ZPHgwQ4YMYfr06ZhM+h9Iyg+DwUD/dvXYMCGQoBbuvLHhIA9E\nbWHvr5mWLk2k2IoM+Y0bN5KXl8eqVauYOHEi8+bNK9zn4+NDTEwMMTExhIaG0qtXLwICAgDIyMhg\nxYoVFBQUAJCTk8OCBQt49913WblyJVlZWXzzzTel1JZI8dWq6sTiR/xYFtaec9l5PLQkiblxaeTk\na8IzqXiKDPmUlBT8/f0BaNu2LampqTccc/nyZaKiopg6dSoAubm5zJgxg5kzZxYe4+joyMqVK6lc\nuTIABQUFODk5lUQPIqWid8s6bAgPZJBfPZYlHKHPws3s0IRnUsHYF3VAVlYWLi4uha/t7OwoKCjA\n3v6PU2NjYwkODsbNzQ2AWbNmMXz4cNzd3QuPMRqN1KxZE4CYmBguX75M165db3rNtLS0YjWTk5NT\n7HMrKlvsGcq273+0dKCNmweRW88Qsnw79zWrxuN+bjg7lu1XWvpd246S7LnIkHdxcSE7+48Fk00m\n03UBD7BmzRoiIyMBOHXqFMnJyRw7dozFixeTmZnJhAkTiIiIwGQy8dprr5Genk5UVBQGg+Gm1/Tx\n8SlWM2lpacU+t6KyxZ6h7Pv28YGHuhXwxvqDrEhKZ9fJPF7u35p7mtcusxr0u7Ydxek5JSXlptuL\nHIr4+fkVfpm6e/dumjZtet3+S5cukZeXh4eHBwDu7u7Ex8cXflbv6upKREQEANOnTyc3N5clS5YU\nfmwjUlFUcbRn2n8mPHP+z4Rn41fu0oRnUq4VGfJBQUE4OjoyZMgQ5s6dy+TJk4mOjmbTpk0ApKen\n4+npWeSF9u3bR2xsLAcPHuSxxx4jLCyMDRs23H4HImXM7/cJz3o04csfMgian8CaPZrwTMqnIj+u\nMRqNzJo167pt3t7ehT/7+vqyZMmSPz0/KSkJgJYtW7J///7i1ilSrjjZ2xEe1JS+revwz9gfGPvh\nLr7YfZzZD7WmjmslS5cnUkgPQ4nchuZ1qvHpM12Y0rc5Ww6dJWh+Ah9+pwnPpPxQyIvcJns7I08H\neLPu2QBaelZj8qd7CX1rBz+fzS76ZJFSppAXKSF31nTmw6fuZu6A1qQezyR4YSJvJR6hQFMjiAUp\n5EVKkMFgYOhdDdgQHki3xrV4eW0aA5duZf/Ji5YuTWyUQl6kFNRxrcRbw9oTNbQdv56/wv2RW5i/\n/gC5BZoaQcqWQl6klBgMBh5oU5eN4YE82KYukV8f4r7ILaQcPW/p0sSGKORFStkdzo7MD2lL9OMd\nuZxbwKA3tzJz9T6ycwssXZrYAIW8SBm5p1lt1ocHEnZ3Q97Z+jO9IhJJPHjG0mWJlVPIi5QhFyd7\nZvVrxccjO+PkYGTYiu947uM9XLisqRGkdCjkRSyg451urB3nz+h7vPls13F6zk9k7d4MS5clVkgh\nL2IhlRzseL53c1aP6UodVydGvf89I2KSOX0xx9KliRVRyItYWMu6rnw+qisv9GnOtwfO0GN+Aqt2\namoEKRkKeZFywN7OyMhAb9aND6CFRzUmfbKXR97ewdHfNDWC3B6FvEg50ug/UyO83L8Ve3/NpPcC\nTY0gt0chL1LOGI0GHunUkPXhAXRrXJOX16YxYOlW0s/lWro0qYAU8iLllIdrZd4a1oGooe04fv4K\nY788zhuaGkFukUJepBz7fWqEDeGBdG/kQlTh1AjnLF2aVBAKeZEKwM3Zkef8a/PO4x25kneVQW9u\n09QI8rco5EUqkO7NahM/IYDHOt/Jv7ddmxrh2wOnLV2WlGMKeZEKxsXJnpkPtiR2ZGcqORj5R/RO\nJqzazblsTY0gN1LIi1RQ7Ru68dU4f8be25g1e04QND+B1XtO6CEquY5CXqQCq+Rgx8RezVgzthv1\n7qjMuA938eS/k8nIvGLp0qScUMiLWAEfj2p8OqorL97nQ9LhswTNTyRm+1FMJo3qbZ1CXsRK2BkN\nPOnvxfrxgbStX51pn6cy5K3tHD6TZenSxIIU8iJWpkGNKsQ8cRevDvJlf8ZF+izczOJvDpGvqRFs\nkkJexAoZDAYe7lCfjRMD6elTm9fiD/DgoiR++PWCpUuTMqaQF7FitatWYskj7Xnz0fb8lpXLQ4uT\nmLM2jSt5mhrBVijkRWxAcKs6bAgPJKRjfZYnHiF4YSJbD521dFlSBhTyIjbCtbIDcwf48uFTd2MA\nQt/ewaTYH8i8nG/p0qQUKeRFbExn7xqsGx/AiEAvYr//lZ4RCaxL1fqy1kohL2KDKjnYMbmPD1+M\n7kotFydGvvc9I2NStL6sFVLIi9iwVp6ufDGmK/8MbsbXB07TU+vLWh2FvIiNc7AzMqp7Y9Y964/P\nf9aXDX1rBz+f1fqy1kAhLyIAeNVy4cOn7mZO/9akHr+2vuybCYe1vmwFp5AXkUJGo4HQTg3YODGQ\nwKa1mBe3n4eWJLHvRKalS5NiUsiLyA3cq1ViWVh7ljzix8nMHB5clMQr6/aTk6+HqCoahbyI3JTB\nYKBvaw82hgcy0M+Tpd8eps/CzWw/8pulS5NboJAXkb9UvYojrw5qw/tPduKqycyQ5duZ/OleMq/o\nIaqKQCEvIn9L18Y1iR8fwNMBXqzaeYyg+QmsSz1p6bKkCEWGvMlkYvr06YSEhBAWFsbRo0cL96Wl\npREWFlb4r3Xr1iQmJhbu37lzJ4GBgYWvv/76awYOHEhISAgfffRRCbciIqWtsqMdU/r68MXobtRw\ncWLkeyl6iKqcsy/qgI0bN5KXl8eqVavYvXs38+bNY+nSpQD4+PgQExMDQFxcHLVr1yYgIACAjIwM\nVqxYQUFBAQD5+fnMnTuX2NhYKleuzNChQ7nnnnuoVatWafUmIqWkdT1XVo/pylubj7Bg409snX+W\nqff58HCH+hgMBkuXJ/+lyJF8SkoK/v7+ALRt25bU1NQbjrl8+TJRUVFMnToVgNzcXGbMmMHMmTML\njzl8+DANGjTA1dUVR0dH2rdvT3Jycgm1ISJl7b8fomquh6jKrSJH8llZWbi4uBS+trOzo6CgAHv7\nP06NjY0lODgYNzc3AGbNmsXw4cNxd3e/7n2qVq1a+NrZ2ZmsrJsvS5aWlnbrnQA5OTnFPreissWe\nwTb7Ls89z/B3ZV0dI/9K/o1eEQk82vYOBrRwxc54+6P68tx3aSnJnosMeRcXF7Kz//jLbDKZrgt4\ngDVr1hAZGQnAqVOnSE5O5tixYyxevJjMzEwmTJjAiBEjrnuf7Ozs60L/v/n4+BSrmbS0tGKfW1HZ\nYs9gm32X955btoBH78lh2ueprEg5xY6MAl4Z6EsrT9fbet/y3ndpKE7PKSkpN91e5Mc1fn5+hV+m\n7t69m6ZNm163/9KlS+Tl5eHh4QGAu7s78fHxxMTEEBMTg6urKxEREXh7e3P06FEuXLhAXl4eycnJ\ntGvX7paaEJHyzb1aJZYP68DSR/w4fSmXfouTmBunlagsqciRfFBQEElJSQwZMgSz2cycOXOIjo6m\nQYMG9OjRg/T0dDw9PYu8kIODAy+88AJPPPEEZrOZgQMHXvdxjohYjz6tPejiXZO5cWksSzjCutST\nzO3fmi6Na1q6NJtTZMgbjUZmzZp13TZvb+/Cn319fVmyZMmfnp+UlFT487333su9995bnDpFpIJx\nreLAvIG+PNi2LlM+3Uvo2zt4uEM9pvZtgWsVB0uXZzP0MJSIlKou3jVZNz6AZ7p788n3x+kxP4G1\nezM0Z30ZUciLSKmr5GDHpODmrB7TlTquTox6/3ueejeFjMwrli7N6inkRaTMtKzryuejujKlb3O2\nHDpD0PxE3tt+FJNJo/rSopAXkTJlb2fk6QBv4scH0Ka+Ky9+nkrI8m0cOn3z52bk9ijkRcQiGtZw\n5r0nOvHaIF8Onsqi78LNRG36ibwCrURVkhTyImIxBoOBwR3qszE8kF4t3Xljw0EeiNrCrmPnLV2a\n1VDIi4jF1arqxKJQP94e1oGLOfkMWLqVmav3kZ1bYOnSKrwi75MXESkrPVu408nLjdfiD/DvbT+z\n4cdTjGjvio3NalCiNJIXkXKlaiUHZvVrRezIzlR2tGP6ppM8u3IXv2XlWrq0CkkhLyLlUvuGbnw1\nrhuPtrmDtXsz6Dk/gU9SftVDVLdIIS8i5ZaTvR2PtL2DteP88arlwsSP9zBsxXf8cu6ypUurMBTy\nIlLuNXGvyscjOvN//Vry/dHz9IpI5K3EIxRc1e2WRVHIi0iFYDQaCOt8JxvCA+niXYOX16bRf8lW\n9p3ItHRp5ZpCXkQqlLrVK/P2Yx1YFNqOjMwrPLgoiXlx+8nJ15z1N6OQF5EKx2AwcL9vXTaGBzKg\nnSdvJhwmeEEiWw+dtXRp5Y5CXkQqrOpVHHltcBvef7ITZiD07R38M3YPmZfzLV1auaGQF5EKr2vj\nmqx7NoARgV6Fc9Z/+cMJ3W6JQl5ErERlRzsm9/Hhi9Fd8XCtxJgPdvHUu8mcuGDbc9Yr5EXEqrTy\ndOWzUV148T4fkg79RtD8BN7d9rPNzlmvkBcRq2NvZ+RJfy/WTwjAr+EdTP9iH4Pe3MrBU5csXVqZ\nU8iLiNWq71aFd4ffxfyH25B+Npv7Ijczf/0Bcgts53ZLhbyIWDWDwcAAv3psDA/kvtYeRH59iL4L\nN/Nd+jlLl1YmFPIiYhNquDixYEg73nm8Izn5Jh5eto0pn+3lYo51326pkBcRm9K9WW3WTwjgiW6N\nWPndMXq+kcC61JOWLqvUKORFxOY4O9kz7f4WfDaqKzVcnBj5XgojYpI5dTHH0qWVOIW8iNisNvWr\ns3pMVyYFN+fbA2fo+UYC720/alW3WyrkRcSmOdgZeaa7N+snBOBb35UXP08lZPk2Dp3OsnRpJUIh\nLyICNKzhzHtPdOK1Qb4cPJVF34WbWbDxYIW/3VIhLyLyHwaDgcEd6rNpYiDBreqwYONP3Be5heSf\nK+7tlgp5EZH/UdPFicih7Yj+R0eu5F1l0JvbePHzinm7pUJeRORP3NP82u2Ww7s24oMdxwian0D8\nvop1u6VCXkTkLzg72TP9gWuTnDKAAAAIXElEQVS3W95RxZERMSmMjEmpMLdbKuRFRP6GNvWrs2Zs\nN/4Z3IxvDpym5/wE3t9R/m+3VMiLiPxNDnZGRnVvzLrxAbSq68rUz8r/7ZYKeRGRW9SopjMfPNWJ\nVyvA7ZYKeRGRYjAYDDzcoT4bw8v37ZYKeRGR21Cr6o23W04tR7NbKuRFRErA77dbPtGtER9+d+12\ny/Iwu6VCXkSkhPw+u+Xno7vi5nxtdsun303mZKblbrdUyIuIlDDfetdmt3yhT3MSDp6h5/wEYrZZ\nZjFx+6IOMJlMzJw5kwMHDuDo6Mjs2bNp2LAhAGlpacyZM6fw2N27d7N48WJ8fHx47rnnyM/Pp1at\nWsybN4/KlSuzevVqoqOjMRqNDBw4kNDQ0NLrTETEghzsjIwM9KZPqzpM/SyVaV/s4/PdJ5g7oDVN\n3auWWR1FjuQ3btxIXl4eq1atYuLEicybN69wn4+PDzExMcTExBAaGkqvXr0ICAhg+fLl9O/fnw8+\n+IDGjRuzatUqAF599VWio6P58MMPiY6OJjMzs/Q6ExEpBxrWcCbmibt4Y3AbjpzJKlxMPCe/bG63\nLHIkn5KSgr+/PwBt27YlNTX1hmMuX75MVFQU7733HgBTpkzBbDZjMpnIyMjgzjvvBKBZs2ZcunQJ\ne3t7zGYzBoOhBFsRESmfDAYDA9vXo3uzWsz+Ko3Irw/x5d4M5vZvTSevGqV67SJDPisrCxcXl8LX\ndnZ2FBQUYG//x6mxsbEEBwfj5uYGXGuooKCAfv36kZuby+jRowFo0qQJAwcOpHLlygQFBVGtWrWb\nXjMtLa1YzeTk5BT73IrKFnsG2+zbFnsG6+v7aV8n2teow6LtZwlZvp3gJlUZ3t6Nqk52hceUZM9F\nhryLiwvZ2dmFr00m03UBD7BmzRoiIyOv2+bg4MDatWvZunUrkyZN4sUXX+Tbb79l06ZNVKlSheef\nf564uDj69OlzwzV9fHyK1UxaWlqxz62obLFnsM2+bbFnsM6+fXxgYMBVFmw8yNtb0knOyOPl/q3o\n3bIOULyeU1JSbrq9yM/k/fz8SExMBK59sdq0adPr9l+6dIm8vDw8PDwKt82cOZPt27cD4OzsjMFg\noGrVqlSqVAknJyfs7Oxwc3Pj4sWLt9SEiIi1qOxox+S+Pnwxuit1XJ14afU+zOaSv/umyJF8UFAQ\nSUlJDBkyBLPZzJw5c4iOjqZBgwb06NGD9PR0PD09rzsnLCyMmTNnsnjxYoxGIzNnzsTT05OQkBBC\nQ0NxcHCgQYMG9O/fv8QbEhGpSFp5uvLF6G7k5F8tle8piwx5o9HIrFmzrtvm7e1d+LOvry9Lliy5\nYX9MTMwN7zV06FCGDh1a3FpFRKySndGAs1ORcVwsehhKRMSKKeRFRKyYQl5ExIop5EVErJhCXkTE\niinkRUSsmEJeRMSKGcyl8YjVbfizR3NFROSvtW/f/oZt5S7kRUSk5OjjGhERK6aQFxGxYqUzWUIZ\n+6slCq1Jfn4+U6ZM4fjx4+Tl5fHMM8/QuHFjXnjhBQwGA02aNGHGjBkYjdb3t/u3335jwIABrFix\nAnt7e5voedmyZXz99dfk5+czdOhQ7rrrLqvvOz8/nxdeeIHjx49jNBr5v//7P6v+fe/Zs4fXX3+d\nmJgYjh49etM+Fy1axLfffou9vT1TpkzB19f31i5itgLx8fHmSZMmmc1ms3nXrl3mkSNHWrii0hEb\nG2uePXu22Ww2m8+dO2cODAw0jxgxwrx9+3az2Ww2T5s2zbx+/XpLllgq8vLyzKNGjTL36tXLfOjQ\nIZvoefv27eYRI0aYr169as7KyjJHRkbaRN8bNmwwjxs3zmw2m81btmwxjxkzxmr7Xr58ufn+++83\nDx482Gw2m2/aZ2pqqjksLMxsMpnMx48fNw8YMOCWr2MVfw7/zhKF1iA4OJhnn3228LWdnR379u3j\nrrvuAiAgIICtW7daqrxS88orrzBkyBBq164NYBM9b9myhaZNmzJ69GhGjhxJ9+7dbaLvRo0acfXq\nVUwmE1lZWdjb21tt3w0aNCAqKqrw9c36TElJoVu3bhgMBurWrcvVq1c5d+7cLV3HKkL+z5YotDbO\nzs64uLiQlZXFuHHjGD9+/HVr5To7O3Pp0iULV1myPv30U9zc3Ar/iANW3zPA+fPnSU1NZeHChbz0\n0ks899xzNtF3lSpVOH78OH369GHatGmEhYVZbd+9e/e+bpW9m/X5v9lWnP6t4jP5v7NEobXIyMhg\n9OjRhIaG8sADD/Daa68V7svOzv7TdXMrqk8++QSDwcC2bdtIS0tj0qRJ141krLFngOrVq+Pl5YWj\noyNeXl44OTlx8uTJwv3W2vc777xDt27dmDhxIhkZGTz22GPk5+cX7rfWvoHrvmf4vc//zbbs7Gyq\nVq16a+9bYhVaUFFLFFqLs2fPMnz4cJ5//nkGDRoEQIsWLdixYwcAiYmJdOjQwZIllrj333+f9957\nj5iYGHx8fHjllVcICAiw6p7h2kMtmzdvxmw2c+rUKa5cuULnzp2tvu9q1aoVhpirqysFBQVW/9/4\n727Wp5+fH1u2bMFkMnHixAlMJhNubm639L5W8TDU73fXHDx4sHCJwv9evcpazJ49m7i4OLy8vAq3\nTZ06ldmzZ5Ofn4+XlxezZ8/Gzs7uL96l4vp9WUmj0ci0adOsvudXX32VHTt2YDabmTBhAvXq1bP6\nvrOzs5kyZQpnzpwhPz+fYcOG0apVK6vt+9dffyU8PJyPPvqI9PT0m/YZFRVFYmIiJpOJyZMn3/If\nOasIeRERuTmr+LhGRERuTiEvImLFFPIiIlZMIS8iYsUU8iIiVkwhLyJixRTyIiJWTCEvImLF/h8E\nVkYTAahIJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = np.random.uniform(size=(100, 2))\n",
    "y_test = np.random.binomial(1, 0.5, size=100)\n",
    "\n",
    "gb_test = GradientBoosting(loss=BCEWithLogitsLoss(), n_estimators=100)\n",
    "gb_test.fit(X_test, y_test)\n",
    "\n",
    "loss_values = gb_test.loss_values\n",
    "plt.plot(loss_values)\n",
    "np.testing.assert_array_equal(loss_values, sorted(loss_values, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Использование класса GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как работает наш бустинг на двух задачах - регрессии и классификации на 2 класса.\n",
    "Для этого будем использовать игрушечные выборки, полученные с помощью `sklearn.datasets.make_regression` и `sklearn.datasets.make_classificaiton`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Задача регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=2, random_state=2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter # 10: Loss value: 2.806925807226479\n",
      "Loss on evalset: 124.96904212004792\n",
      "Iter # 20: Loss value: 0.19805745981229372\n",
      "Loss on evalset: 116.92133242249149\n",
      "Iter # 30: Loss value: 0.017310059714994334\n",
      "Loss on evalset: 117.90013919790786\n",
      "Iter # 40: Loss value: 0.0026099669324611456\n",
      "Loss on evalset: 117.6705256699327\n",
      "Iter # 50: Loss value: 0.0002338105644218913\n",
      "Loss on evalset: 117.88277135831198\n",
      "Iter # 60: Loss value: 3.371777929125901e-05\n",
      "Loss on evalset: 117.97015865791762\n",
      "Iter # 70: Loss value: 2.889430551314456e-06\n",
      "Loss on evalset: 117.95891774979023\n",
      "Iter # 80: Loss value: 3.256360307171583e-07\n",
      "Loss on evalset: 117.96987132308246\n",
      "Iter # 90: Loss value: 4.410230625611496e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 100: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 110: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 120: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 130: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 140: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 150: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 160: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 170: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 180: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 190: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 200: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 210: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 220: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 230: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 240: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 250: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 260: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 270: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 280: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 290: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 300: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 310: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 320: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 330: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 340: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 350: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 360: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 370: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 380: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 390: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 400: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 410: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 420: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 430: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 440: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 450: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 460: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 470: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 480: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n",
      "Iter # 490: Loss value: 4.4102306256118714e-08\n",
      "Loss on evalset: 117.97365723524979\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoosting(loss=MSELoss(), n_estimators=500, learning_rate=1.0, max_depth=3)\n",
    "gb_regressor.fit(X, y, X_evalset=X_val, y_evalset=y_val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBQAAAD0CAYAAAArFHUNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(gb_regressor.loss_values, label='train loss')\n",
    "plt.plot(gb_regressor.loss_values_evalset, label='evalset loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке выше вы должны видеть два графика - лосс на обучающей и на валидационной выборках по итерациям бустинга.\n",
    "\n",
    "Проверим, что наш бустинг действительно работает: сравним предсказание типа \"среднее по датасету\" с предсказаниями бустинга для обучающей и валидацонной выборок - после 500 итераций они должны отличаться как минимум в 100 раз.\n",
    "\n",
    "*Код в ячейках ниже должен выполняться без ошибок.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE для предсказания среднего по выборке: 1648.606\n",
      "MSE для предсказаний бустинга: 0.081\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_mean = np.mean(y_train) * np.ones_like(y_train)\n",
    "mse_baseline = mean_squared_error(y_train, y_mean)\n",
    "print('MSE для предсказания среднего по выборке: {:.3f}'.format(mse_baseline))\n",
    "\n",
    "y_pred = gb_regressor.predict(X_train)\n",
    "mse_boosting = mean_squared_error(y_train, y_pred)\n",
    "print('MSE для предсказаний бустинга: {:.3f}'.format(mse_boosting))\n",
    "\n",
    "np.testing.assert_array_less(mse_boosting, mse_baseline / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE для предсказания среднего по выборке: 3531.394\n",
      "MSE для предсказаний бустинга: 0.081\n"
     ]
    }
   ],
   "source": [
    "# Val\n",
    "y_mean = np.mean(y_val) * np.ones_like(y_val)\n",
    "mse_baseline = mean_squared_error(y_val, y_mean)\n",
    "print('MSE для предсказания среднего по выборке: {:.3f}'.format(mse_baseline))\n",
    "\n",
    "y_pred = gb_regressor.predict(X_val)\n",
    "mse_boosting = mean_squared_error(y_val, y_pred)\n",
    "print('MSE для предсказаний бустинга: {:.3f}'.format(mse_boosting))\n",
    "\n",
    "np.testing.assert_array_less(mse_boosting, mse_baseline / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Задача классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, n_repeated=0, n_clusters_per_class=1, flip_y=0.25, random_state=2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoosting(loss=BCEWithLogitsLoss(), n_estimators=500, learning_rate=1.0, max_depth=3)\n",
    "gb_classifier.fit(X_train, y_train, X_evalset=X_val, y_evalset=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAAD0CAYAAADNPb5JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4leXh//H3yRlZJ3uTBQkEEgIE\nwkaGMmSIA8FiXVito621rVqtivrtjwJWxVYFFAcVJy5QS0EFkSkoIUGDYa8AkhASIIPMc35/PJkI\nBIWQ5PB5Xdd9nfPMcz+5bmPOh3uYnE6nExERERERERGRRrg1dwVEREREREREpHVQiCAiIiIiIiIi\nZ0UhgoiIiIiIiIicFYUIIiIiIiIiInJWFCKIiIiIiIiIyFlRiCAiIiIiIiIiZ8XSXB+clpbWXB8t\nIiIiIiIiImeQmpp6yv3NFiLA6SvVkmVlZZGYmNjc1RA579S2xVWpbYurUtsWV6W2La6qNbXtM/2j\nf6MhgsPh4IknnmDr1q3YbDamTJlCbGwsYPwQpk6dWntuRkYGM2fOpGvXrlx++eUkJCQAMGzYMG65\n5ZZzfQ4RERERERERaUaNhghLly6lvLyc+fPnk5GRwfTp05k9ezYAiYmJvPHGGwAsXryY0NBQBg0a\nxNq1a7niiiuYPHly09ZeRERERERERC6YRidWTEtLY+DAgQCkpKSQmZn5k3NKSkp4/vnneeSRRwDI\nzMxk8+bN3Hjjjfzxj38kNzf3PFdbRERERERERC60RnsiFBUVYbfba7fNZjOVlZVYLHWXfvDBB4wc\nOZLAwEAA4uLiSE5Opn///nzyySdMmTKF55577if3zsrKOh/PcEGVlpa2ynqLNEZtW1yV2ra4KrVt\ncVVq2+KqXKVtNxoi2O12iouLa7cdDkeDAAHg008/bRAS9O3bF09PTwCGDx9+ygABaDWTStTXmibD\nEPk51LbFValti6tS2xZXpbYtrqo1te0zTazY6HCGHj16sHLlSsCYOLFmssQahYWFlJeXExERUbvv\n0Ucf5bPPPgPg66+/pnPnzr+o4iIiIiIiIiLScjTaE2H48OGsWbOGiRMn4nQ6mTp1KnPnziUmJoah\nQ4eye/duIiMjG1xz33338fDDD/POO+/g6enJlClTmuwBREREREREROTCaDREcHNz4+9//3uDffHx\n8bXvu3btyqxZsxocj46Orl21wVU4nU6unrUWP3MF/2zTjnA/j+aukoiIiIiIiDSxsrIyPvnkEyZM\nmHBW53/00Uf4+fkxdOjQRs+97LLLWLx4Me7u7udazQum0eEMYjCZTFyd0oZ12SUMfeYrXlm1i8oq\nR3NXS0RERERERJrQ4cOHef/998/6/HHjxp1VgNBaNdoTQercOqAdsdZC3thcypRFWXy48QBTrk4m\nNTaguasmIiIiIiLi8j5M2897G7LP6z2v6xnNtalRpz3+4osvsmPHDl544QWcTifp6emUlJTwj3/8\ng4ULF5KZmUlxcTHx8fFMmzaN559/nuDgYOLi4nj55ZexWq3s37+fXr168dhjj53yM/bv388jjzxC\nZWUlJpOJRx99lE6dOvHQQw+xb98+ysrKuO222xg9ejTPPvss69atw+FwMGbMGCZNmnRefx6NUU+E\nnynCx8prk3rx4o09OFpSzrWz1/LQh99RUFze3FUTERERERGR8+yuu+6iffv2/OEPfwAgLi6Od999\nl7CwMHx9fZk7dy7vvvsuGRkZ5OTkNLj24MGDPP/888yfP58FCxac9jP++c9/ctNNN/HWW2/xyCOP\n8PDDD1NUVMT69et54YUXePnll6mqqgJg4cKFPP3007z11lt4eFz4YfbqifALmEwmRiZHMLBDCP9a\nuo3X1uzh8x9yeGhUJ8b3iMLNzdTcVRQREREREXE516ZGnbHXwIXQrl07ANzd3cnPz+cvf/kLXl5e\nlJSUUFFR0eDchIQELBYLFosFm8122nvu3LmTXr16AZCYmMihQ4ew2+1MnjyZyZMnU1RUxJVXXgnA\njBkzmDFjBnl5eQwcOLCJnvL01BPhHHi7W3hkTBKL/ngJccHe/PWD7/jVnK/ZeqiwuasmIiIiIiIi\n54GbmxsOh6PBNsDKlSv58ccfmTFjBn/5y18oLS3F6XQ2uNZkOrt/YI6Pj2fDhg0AZGVlERwcTG5u\nLps3b2bmzJnMmTOHp556ivLycpYsWcKMGTN4/fXXWbBgAQcOHDhPT3p21BPhPOgU7st7d/bjg7T9\nTFucxejnVnHbJe24d2gHvN31IxYREREREWmtgoKCqKio4KmnnmowfKBmpcLrrrsOm81GdHQ0ubm5\nv+gz/vrXvzJ58mRee+01Kisr+cc//kFISAiHDx/m6quvxsvLi9/85jfYbDb8/Py46qqr8PPzY8CA\nAbRp0+Z8PepZMTlPjkoukLS0NFJTU5vjo89JVlYWiYmJpz1eUFzOk0u28O632YT7evC30Z24slub\ns06gRJpLY21bpLVS2xZXpbYtrkptW1xVa2rbZ/q+ruEM51mAt43p13blw7v7E+Ljzr3vZvCrOevI\n+vF4c1dNRERERERE5JwoRDhbTie8eAkxy38Pu74yts8gNTaAhb8fwNRrurA9p5Axz63i8Y8zOVZS\nccbrRERERERERFoqhQhny2SCPndjK9wH866CV4bBlv+dMUwwu5n4dZ8Ylt8/hBv7xvLGur1c+sxX\nvPPNPqoczTKKREREREREROQXU4jwc3S/gZ1jPoQrnoXiw/Du9TB7AHz/ATiqTnuZv5eNv1+VzH/v\nGUj7EDt/++h7rpm1hvR9BRew8iIiIiIiIiLnRiHCz+Q026Dnb+CejXDNS+CohA9vgxd6wsZ5UFl+\n2muT2vgy/86+/HtiCjnHS7lm1lruf38ThwvLLuATiIiIiIiIiPwyChF+KbMFuk2E362D6+aBzQ6f\n3APPdYf1L0HFiVNeZjKZuColkmX3DeGuwfF8nHGAy57+ipdX7qK80nHKa0RERERERERaAoUI58rN\nDZKugjtXwg0fgn80LP4r/KsLrHwaTpx6yILd3cJDozrx2Z8G0bNtAP/4XxYjnl3B55sP0UyrboqI\niIiIiMh5tn79ev785z//rGvKysp4//33f7L/pptuYufOneerar+IQoTzxWSCDsPgN0tg0v8gvCt8\n+f9gRmdY8jc4mn3Ky+JC7My9tTf/ubUXFrMbd7yRxg2vrNeSkCIiIiIiIhepw4cPnzJEaAkszV0B\nl9R2gFEOfQ9rn4dv5hhDHLqMh/5/hPDkn1wypGMol7QP5u1v9jHji22MeW4Vv+oVw30jEgi2uzfD\nQ4iIiIiIiLQwGe9A+pvn957db4SU6097uKKigscff5y9e/ficDj405/+hJ+fH1OnTmXevHkA3Hnn\nndx7773s27ePt956q/baf//73w3u9dBDD7Fv3z7Kysq47bbbGD16NN988w3PPvssZrOZ6Oho/v73\nv/Piiy+yY8cOXnjhBf7whz/8pE7Hjx/ngQceoKioiKqqKu6991769evHs88+y7p163A4HIwZM4ZJ\nkybx1ltvsXDhQtzc3OjRowcPPvjgOf24Gg0RHA4HTzzxBFu3bsVmszFlyhRiY2MByMrKYurUqbXn\nZmRkMHPmTJKTk7n//vspLS0lNDSUadOm4enpeU4VbZXCu8C4OXDZZFg3G9L+A9/Nh/ihMOCP0G6w\n0YOhmsXsxs392nJVt0j+vWw7877ew6ebDnLPZe2ZNKAt7hZzsz2KiIiIiIjIxej9998nICCAqVOn\nUlBQwI033siiRYsoKyvjwIEDWK1WCgoKSEpKYuXKlcyZMwdPT08ee+wxVq9eTVhYGAAnTpxg/fr1\nfPjhhwCsWbMGp9PJ5MmTefvttwkKCuJf//oXCxYs4K677mLbtm2nDBAAZs+eTf/+/bnlllvIycnh\n+uuvZ+nSpSxcuJA333yTsLAwPvroIwA++ugjJk+eTEpKCm+//TaVlZVYLL+8P0GjVy5dupTy8nLm\nz59PRkYG06dPZ/bs2QAkJibyxhtvALB48WJCQ0MZNGgQU6ZM4YorrmDcuHHMmTOH+fPnM2nSpF9c\nyVbPPxpGToXBD8CG12DdizDvKojoZvRMSLramKixmp+XlcfGJnFD3ximLspi2uItvLV+Hw+PTuTy\nzmGY6gUPIiIiIiIiF42U68/Ya6ApbNu2jbS0NL777jsAKisrKSgoYPz48SxcuBCbzca4ceMACAoK\n4sEHH8Tb25tdu3aRkpJSex9PT08mT57M5MmTKSoq4sorryQ/P5/c3Fz+9Kc/AVBaWsqAAQMardPO\nnTsZO3YsAGFhYdjtdvLz85kxYwYzZswgLy+PgQMHAjBt2jRee+01nn76aVJSUs55Dr5GQ4S0tLTa\nD09JSSEzM/Mn55SUlPD888/z5ptv1l5z5513AjBo0CBmzJhxcYcINTwDYOB90Pf3Ro+Etc8Zy0Mu\n+zv0vdvoRuPuU3t6fIidVyf1YtX2w0z5bxZ3vZlGn3aBTL4iieRIv2Z8EBERERERkYtDXFwc4eHh\n3HXXXZSWljJ79mz8/PwYPXo0kyZNwmQy8dprr1FYWMhzzz3HV199BcCtt97a4At7fn4+mzdvZubM\nmZSVlTF48GDGjh1LeHg4s2bNwsfHh2XLluHl5YWbmxsOx+lX74uPj2fDhg0kJSWRk5PD8ePH8fX1\nZcmSJcyYMQOn08mYMWMYM2YM7733Hv/3f/+Hu7s7t912G+np6fTu3fsX/zwaDRGKioqw2+2122az\n+SfdHz744ANGjhxJYGBg7TU+PsaXYW9vbwoLC09576ysrF9c8eZSWlp6furt1RuGzsN+YBVBW9/C\na8lDVC37fxxtN5aChOuo8G5Te2ow8MyIYJZsd2deej5XPL+aS+Ps3NI9gDC79dzrIsJ5bNsiLYza\ntrgqtW1xVWrb0tKkpKQwc+ZMxo0bR0lJCaNGjWLr1q2A0QvA4XCQnZ2N0+mkffv2jB49Gnd3d+x2\nO5s3b6aqqorjx4/j6enJ9u3bGTlyJB4eHowdO5adO3dy0003cdNNN+FwOPDy8uLee+/l8OHDFBYW\n8tBDD3HLLbfU1qW4uJhdu3Zx6aWX8vzzz7NgwQLKy8v57W9/y86dO6moqGDkyJF4e3uTlJTEsWPH\n8PX15YorrsDPz4/AwEDc3d3P6b8xk7ORvgzTpk2jW7dujB49GjB6FqxcubLBORMmTOC5554jIiIC\ngGuuuYZXXnmFoKAgtmzZwrPPPstLL73U4Jq0tDRSU1N/ccWbS1ZWFomJief/xvvTYN0s+GEhOB3Q\n6Qro+zuI6dtg3oTjpRW8+NVOXl29Gydwa/+2/G5Ie/y8FCbIuWmyti3SzNS2xVWpbYurUtsWV9Wa\n2vaZvq83usRjjx49akODjIwMEhISGhwvLCykvLy8NkCouWbFihUArFy5slWGBRdcVCqMfxXu/Q4G\n3Au7V8LckfDypfDde1BZDoCvh5W/juzE8vuHMLZrG+as2sXgp5fzyqpdlFVWNfNDiIiIiIiIiCtr\nNEQYPnw4NpuNiRMnMm3aNP72t78xd+5cli1bBsDu3buJjIxscM3dd9/NokWLmDhxIunp6dx4441N\nU3tX5BcJw56Av/wAY2ZAWRF89Fv4d1dY9QyU5APQxt+TZ67rxqJ7BtIl0o8pi7IYNmMFn246eM4T\nZYiIiIiIiIicSqPDGZqKhjOcJYcDdi4zhjrs/BIsntB1AvT6LUR0rT1t5bbDTP1fFlsOFdItyo+H\nRyfSJy7owtVTWr3W1L1K5OdQ2xZXpbYtrkptW1xVa2rbZ/q+/ssXh5QLw80NOgw3Sm4WrJsN378P\nG+dBdF/o/VtIvJJBCSEMaB/MgvQDPPP5Vn41Zx3DEsN4cGRHOoT5NP45IiIiIiIiIo1odDiDtCCh\niXDlc8ZQh8unQnGusUTks53hy39gLvqR8alRLL9/CA9c3pF1u45w+b9Wct97m8jOL2nu2ouIiIiI\niEgrpxChNfIMgH6/hz+kwY0fQmQPWPkUPJsM82/CY/8afj8knpV/vZTbLmnHp98d5LJnvuKJTzaT\nV1TW3LUXERERERGRVkrDGVozNzdoP8woBXtgw2vGMIesTyCkE4G9bueRYRO5dUA7nlu2nTfW7eW9\nDdncdkk7fjsoDl8PLQspIiIiIiIiZ089EVxFQFsY/nf4SxZcNQusnvC/++GZRNqsmcz0Syx88edB\nXNoplOe/3MGgfy7npRU7Ka3QspAiIiIiIiJydhQiuBqrJ3S/Ae74Cm7/EjqNgY2vw+x+xH18DTMT\ns1h0dyrdovyZtngLQ576irfX76OiytHcNRcREREREZEWTiGCK4tKhXEvwV+2GBMxlh6Fj39H57d7\n83rYe3wy3o82/h48vOB7Rjy7kk82HcThaJYVP0VERERERKQVUIhwMfAOMiZi/P03cOti6DgSNs6j\n63/H8KF1Mv+7ZDe+bmX88Z10rnh+NUt/yMHpVJggIiIiIiIiDSlEuJiYTBDbH8bNgfu2wMjpmMqL\nSdrwCAtLb+PLTh/T5sRWbp+3gatmrmH5llyFCSIiIiIiIlJLqzNcrLwCoe/d0OcuyP4GU9p/iNv8\nEa9Uzic/LIlXjw3ij//pSXx0G/4yPIGBHYIxmUzNXWsRERERERFpRuqJcLEzmSCmD1wz2+idMOop\nAt1NPFDxIulev+fuI9N46T+vMmH2GtbsyFPPBBERERERkYuYeiJIHc8A6HMH9P4tHNyIJf0tRmR+\nwOWOVRzKDea9/1zCuxFXcsOoIfSNC2ru2oqIiIiIiMgFphBBfspkgshUiEzFdPlU2LqIkI1vcs+u\njzEdXsj6/3TixcDR9Bx9Kz0TYpq7tiIiIiIiInKBKESQM7N6QPK1mJOvhWMHqEh/h07fzKPP0RkU\nvzWTld6DCBv0Gzr2HgluGh0jIiIiIiLiyvStT86eXyTWIffj98Amym5eTHab0fQoWU3HJdeT+49E\nsj96DOeRnc1dSxEREREREWki6okgP5/JhHtcfzrd2Z+S4uMsX/Q63lnz6bnpOUzf/ZtjQSn49v41\npuRrwTu4uWsrIiIiIiIi54l6Isg58fL25dLr7qHrwyv4aMhnvGC+mYOH8zEt/iuOpxNwvnUdfP8B\nlJc0d1VFRERERETkHDXaE8HhcPDEE0+wdetWbDYbU6ZMITY2tvb4ihUrmDlzJgBJSUk8/vjjAAwa\nNIi2bdsCkJKSwn333dcE1ZeWwsNqZvylfSgf2IuPNu7nyS+X0adoGeN3fE3I9s9w2uyYEsdClwnQ\nbjCY1QlGRERERESktWn0m9zSpUspLy9n/vz5ZGRkMH36dGbPng1AUVERTz31FPPmzSMwMJCXX36Z\ngoICCgsL6dy5My+++GKTP4C0LDaLGxN7xzA+9RY+/W441y/bRnB+GjdZ1zN883+xbXoH7GGQPB66\nToCIFGM1CBEREREREWnxGg0R0tLSGDhwIGD0KMjMzKw9lp6eTkJCAk8++STZ2dlMmDCBwMBA1q1b\nR05ODjfddBMeHh787W9/Iy4urumeQloci9mNa7pHcWW3SJZkJvL8l334y6EbmOD7A3d6pxH1zRxM\n62ZCUHvoPA6Sx0FoYnNXW0RERERERM6g0RChqKgIu91eu202m6msrMRisVBQUMD69etZuHAhXl5e\n3HDDDaSkpBASEsIdd9zBqFGj2LBhAw888AAffvjhT+6dlZV1fp/mAigtLW2V9W5OcVaYMSKY9fu9\neGeTD2/uTaGd56+5v80mBlaswWfV05hW/pNS3zgKY4ZyPHoY5b6xjd9Yziu1bXFVatviqtS2xVWp\nbYurcpW23WiIYLfbKS4urt12OBxYLMZl/v7+dOnShZCQEAB69uxJVlYWl156KWazuXZfTk4OTqcT\n00nd1hMTW9+/PGdlZbXKercESUkwabiTVdvzmP3VTn6/yxNfj0u4K9XOTX6b8NnxKR6ZrxCS+TKE\ndYHka4xeCoHtmrvqFwW1bXFVatviqtS2xVWpbYurak1tOy0t7bTHGl2doUePHqxcuRKAjIwMEhIS\nao8lJyezbds28vPzqaysZNOmTbRv354XXniB119/HYAtW7bQpk2bnwQIcnEymUwMSgjhnTv6svD3\nA+gfH8xTa4+S+nk7Hgn4J/tv3QCXTwOrByz7OzyXAnOGwJrn4Gh2c1dfRERERETkotZoT4Thw4ez\nZs0aJk6ciNPpZOrUqcydO5eYmBiGDh3Kfffdx+233w7AyJEjSUhI4I477uCBBx5gxYoVmM1mpk2b\n1uQPIq1PSrQ/L96Uys7DRby8chfvb9jPO984GNWlL3ePuoFk72OweYFRvphslKhekHQ1JI6FAA15\nEBERERERuZBMTqfT2RwfnJaWRmpqanN89DlpTV1QWpvc46W8umY3b6/bR2FZJZe0D+auwfEMaB+E\nqWC3ESZkLoCc740LIroZYULiVRCScOabS6PUtsVVqW2Lq1LbFlelti2uqjW17TN9X2+0J4LIhRLq\n68HfRiXy+0vb89a6fby2Zjc3vrqeLpF+3Dk4jlED/oJ54H2Qvwuy/gtZn8CXU4wS3NEIFJKuhPCu\nWjZSRERERESkCShEkBbH18PK3UPiuXVAWxakH2DOyl384e10ogO38JsB7ZjQMwb7gD/CgD/C8YOw\nZZERKKyeAaueBv8YSLzSKFG9wK3RqT9ERERERETkLChEkBbLw2rm+t4xXNczms83H+KV1bv5v09/\nYMYX2/h17xhu6d+WNv5toPdvjVJ8BLb+D7I+hW/mwNcvgD0cOo0xSttLwOLe3I8lIiIiIiLSailE\nkBbP7GZiVJcIRnWJYOO+Al5dvZuXV+3ildW7GdMlgtsHtqNrlD94B0GPm4xSegy2f2H0UNj0Dmx4\nFWw+0H4odBwNHYaDV2BzP5qIiIiIiEirohBBWpUeMQH0+HUA2fklvL52D+9+m80nmw7Su10gt1/S\njqGJYZjdTODhB13GG6XiBOxeBVsXwdYl8MNCMLlBTD8jUOg4CoLim/vRREREREREWjyFCNIqRQd6\n8egVSdw7rAPzv81m7po93PFGGm2DvPjNJe0YnxqFl626eVs9IWGEUcY44Md02LrYKJ8/YpTgBCNM\n6Di6eh4Fc/M+oIiIiIiISAukEEFaNR8PK7cPjGNS/7Z8tjmHl1ft4rGPN/PM59v4dZ8Ybu4XS4Sf\nZ90Fbm4QmWqUyx6Fgr2wbYkxl8LXM2HNv8ErCDpcboQO8ZcZvRpEREREREREIYK4BovZjTFdIxjT\nNYK0vQW8unoXL63YyZyVuxjZOZxb+relV9sATCcv/RgQC33uNErpMdixtLqXwiLY9Da4WSC6rzGH\nQsLlENJJy0eKiIiIiMhFSyGCuJzU2ABSY1PJzi/hzXV7effbbBZ9/yOJEb5M6h/LVSmReFhPMVzB\nww+SrzVKVSXs/xa2f25M0Lj0caP4RRuBQocR0G4Q2Lwv/AOKiIiIiIg0E4UI4rKiA7342+hE/jQs\ngYUZB3h97R4e/PB7pi3ewsReMdzUL5ZIf89TX2y2QGw/owx7HI4dgB1fGIHCpvmw4TUwuxvLRnYY\nYQQLmpxRRERERERcnEIEcXmeNjPX945hYq9o1u3K5/W1e5izcidzVu5kRJIx1KFvXOBPhzrU5xcJ\nqZOMUlkGe9cagcL2z2HJg0YJal8XKMQOAIv7hXpEERERERGRC0Ihglw0TCYT/eKD6BcfxP6CEt5c\nt493v93Hks2H6BTuw8392nJN90g8bY2szGBxh/hLjTJyKuTvqgsUvn0V1s0Cqze0Gwhx1ecFJ2gu\nBRERERERafUUIshFKSrAi4dGdeJPwzrwccYB/rN2Lw8v+J4nl2xhfGoUN/SJIS7EfnY3C4yrm5yx\nvAT2rIJtn8HOL42VHwB8IyFuiBEqxA0Be0jTPJiIiIiIiEgTUoggFzUPq5lf9Yrhup7RfLungNe/\n3sPra/fw6urd9I8P4sa+sQxPCsNqdju7G9q8jFUcEi43tgv2wM7lsGs5bFkEGW8Z+8O71PVSiOkH\n1tPMzSAiIiIiItKCKEQQwRjq0LtdIL3bBZJbWMp732bzzjfZ/O6tjYT6uDOxVzQTe8fQ5nQTMZ5O\nQFvoeatRHFXwY4bRQ2HnV7BuNqx9DiweRpAQf6kRLIQlg9tZhhYiIiIiIiIXkEIEkZOE+njwh8s6\ncPeQ9izfkstb6/fy/PIdvLB8B5d1CuPGvjEM6hCCm9vPnOPAzQyRqUYZ9ACUFRkTNO5abvRW+OIx\n4zyvYGPIQ02o4Bd5vh9RRERERETkF2k0RHA4HDzxxBNs3boVm83GlClTiI2NrT2+YsUKZs6cCUBS\nUhKPP/44ZWVlPPDAAxw5cgRvb2+efPJJAgMDm+4pRJqA2c3EsKQwhiWFkZ1fwtvf7OO9b7NZmpVD\nTKAXv+4Tw4TUKILsv3AVBnc7JIwwCsDxg7Drq+rhD19B5gfG/uCORqDQbrCx5KRnwPl4PBERERER\nkZ+t0RBh6dKllJeXM3/+fDIyMpg+fTqzZ88GoKioiKeeeop58+YRGBjIyy+/TEFBAR9//DEJCQnc\nc889LFq0iFmzZvHoo482+cOINJXoQC8eHGlMxPjZ5hzeXLeX6Yu3MOPzbYzqEs7EXjGNLxPZGN82\nkPJrozidkLO5rpdC2n9g/YuAyZhPoe0lRonpB14K6ERERERE5MJoNERIS0tj4MCBAKSkpJCZmVl7\nLD09nYSEBJ588kmys7OZMGECgYGBpKWlcfvttwMwaNAgZs2a1UTVF7mw3C1mruzWhiu7tWFbTiFv\nrdvLRxsP8HHGQdoFe/OrXtFc2yOKEJ9f2DuhhskE4clG6X8PVJTCgTTYs9pY/WHDa8ZSklSfF1sd\nKsT2V6ggIiIiIiJNptEQoaioCLu9bqk7s9lMZWUlFouFgoIC1q9fz8KFC/Hy8uKGG24gJSWFoqIi\nfHx8APD29qawsPCU987KyjpPj3HhlJaWtsp6S9OYmGDm6rgoVu8tZsm2QqYv3sJTS7bQN9qLyzv4\n0qONJ+afO3fCaQVC2JUQdiWmnuV45P+Ad+5GvHI34rnhNdzWz8aJiTK/eEpCexglpDtV7n5ndXe1\nbXFVatviqtS2xVWpbYurcpXmStkmAAAgAElEQVS23WiIYLfbKS4urt12OBxYLMZl/v7+dOnShZAQ\nY837nj17kpWV1eCa4uJifH19T3nvxMTEc36ACy0rK6tV1luaVvcucA+wI7eI+d/u48ONB1iz7xCR\n/p5M6BnFhJ7RRP7clR0a1Q243nhbWQYHNmLasxqPPavw2P0pgdvfM46Fdq4b/hA7ALyDTnk3tW1x\nVWrb4qrUtsVVqW2Lq2pNbTstLe20xxoNEXr06MHy5csZPXo0GRkZJCQk1B5LTk5m27Zt5Ofn4+vr\ny6ZNm7juuuvo0aMHK1asoGvXrqxcuZLU1NTz8yQiLVz7UDuPjEnigcs78cUPObz77T7+tXQ7/162\nncEJIUzsFcPQxFCs5vO8hKPF3Zh0MbYfDH4AKsvh4EZj6MOe1bBxHnzzknFuaFLd0IfovuAbcX7r\nIiIiIiIiLqvREGH48OGsWbOGiRMn4nQ6mTp1KnPnziUmJoahQ4dy33331c5/MHLkSBISEoiOjubB\nBx/k+uuvx2q18swzzzT5g4i0JDaLG2O6RjCmawTZ+SW8tyGb9zZkc9ebaQTb3bk2NZIJqVG0D/Vp\nmgpYbBDT1yiDakKF9LpQIf1N+GaOca5/DET3JcAaAwFXGyGDm7lp6iUiIiIiIq2ayel0Opvjg9PS\n0lplD4XW1AVFWpbKKgcrth3mnW+yWb41lyqHk5Rof8anRjG2Wxv8PK0XsDLlcOh7yF4H+9ZB9noo\nyjGO2XwgqqcRQET3Md67N1HYIXIB6Pe2uCq1bXFVatviqlpT2z7T9/VGeyKIyPlhMbsxNDGMoYlh\n5BaW8nH6Qd5Py+bRhZn8/b8/cHnncManRnFJ++DzOBnj6Spjg6hUo/T7PTid7NjwJe1teUawkP0N\nfDUdcILJDcI6G0MfaoIFvyhjBQkREREREbmoKEQQaQahPh78dlActw9sx/cHjvFB2n4+zjjIp5sO\nEu7rwbgekYxPjSIuxN74zc4Hk4kKextIHArdfmXsKz0G+781AoV96yDjbfj2ZeOYTxuI6WMEC9G9\nIbwrmPXrRERERETE1emvfpFmZDKZ6BrlT9cofx4Zk8jSH3L5IC2bF1fsZNZXO0mNDWB8ahRjukbg\n63EBhzsAePhB+2FGAaiqhNzNsG999TCI9bB5gXHM6gWRqfWGQPQCT/8LW18REREREWlyChFEWgh3\ni7l2Msbc46V8lH6AD9L287ePvueJTzYzMjmcCanR9IsPavrhDqditkBEN6P0ucPYd2y/MZ/CvvXG\n66oZ4KwCTBCaaPRSiO5r9FoIaKchECIiIiIirZxCBJEWKNTXg7sGx3PnoDg27T/G+xuy+WTTQT7O\nMIY7XJXShqu7R5IY4du8FfWLMkrytcZ2WREcSDOGQGSvg8wFkPYf45hnALTpXq/0AN82ChZERERE\nRFoRhQgiLZjJZCIl2p+UaH8mX5HEFz/ksDD9AK+u3s1LK3fRKdyHq7tHclVKGyL8PJu7uuBuh7jB\nRgFwOODwFqOXwsF0OLgR1vwbHJXGce9QI1CI7FEXLthDm6/+IiIiIiJyRgoRRFoJD6uZsd3aMLZb\nG44UlbHo+x9ZkH6A6Yu38OSSLfRtF8Q13SMZ2SX8ws+fcDpubhCWZBRuNfZVnICczXBgY3WwkA7b\nPweqV5v1jYI2KXXhQkQKeAU21xOIiIiIiEg9ChFEWqEguzs392vLzf3asievmI8zDrIw4wB//fA7\nHv04k+GJYVzdPZLBCSHYLG7NXd2GrJ4Q1dMoNcqK4NB3RqBQEy5s+W/d8YB2dT0VInsY8zK4+1z4\nuouIiIiIXOQUIoi0cm2Dvbl3WAf+OLQ9m/YfY2H6AT7ddJBF3/+Iv5eVMV0iuKZ7JKmxAZha6vwD\n7naI7W+UGieOwo8Zdb0V9m+AzR9VHzRBcAdjXoWacCG8C9i8mqX6IiIiIiIXC4UIIi6i/vwJj4xJ\nZPX2PBakH+DDjft5a/0+ogM9Gdu1DVd0bUNihE/LDRRqePpD3BCj1CjOg4MZxtwKB9Nh11fw3bvG\nMZPZWBGiTUpduBDWGSzuF7zqIiIiIiKuSiGCiAuymt24tFMol3YKpaisks8yD7Ew4wAvrdzFrK92\nEh/izdhuRqDQPtTe3NU9e97B0GGYUWoc/7Fu0saD6bDlf5D+pnHMbDOChJreCmGdISRRPRZERERE\nRH4hhQgiLs7ubuHa1CiuTY3iSFEZSzYf4tNNB/n3su38a+l2EiN8GdstgkSvChKbu7K/hG+EUTqN\nNradTji6r24YxMGN8P0HsOG16gtMEBhnBAo1JTTJmHfBrYXNHyEiIiIi0sIoRBC5iATZ3bmhTyw3\n9Ikl53gpi777kf9+d5B/LtkKQLdvCxnbNYIrurYh3M+jmWv7C5lMEBBrlM5XG/scDijYDbk/GCtD\n1JSsT6ldFcLqZQyHCE2CsGRjRYnQzuAd1GyPIiIiIiLS0ihEELlIhfl68JtL2vGbS9qRnV/C3GWb\nWP9jJVMWZfGP/2XRKzaQsd0iGNUlgmB7K59XwM0NguKNkji2bn95MRzeAjnV4ULuZtj6P0h/o+4c\ne3h1j4XqcCE0CUI6aq4FEREREbkoKUQQEaIDvZiQ7M9jExLZdbiI/373I59sOsjkjzfz+Ceb6R8f\nzKgu4YxICifEx4W+PNu8ITLVKDWcTijKhZzMhj0X1r8EVeXGOSazsTpEzVCImp4LftFGTwgRERER\nERelEEFEGogLsfPHoR2457L2bM0p5NNNB/nf94d4ZEEmkxdm0qttIKO7RDAyOZww31Y65OFMTCbw\nCTNK+6F1+6sqIX+nES7U9FzY/y1kflh3jrtvdaiQVB0wVPdg8PC78M8hIiIiItIEGg0RHA4HTzzx\nBFu3bsVmszFlyhRiY2Nrj0+ZMoWNGzfi7e0NwKxZs6iqquLyyy8nISEBgGHDhnHLLbc00SOISFMw\nmUx0CvelU7gv94/oyNacQhZ/f4jFmT/y+CdGD4WesQGMTA5nVJcIIv09m7vKTctsMYYxhHSE5Gvr\n9pceh9ysej0XfoDvP6w3kSNGD4XaXgvVr4FxYHXBEEZEREREXFqjIcLSpUspLy9n/vz5ZGRkMH36\ndGbPnl17fPPmzbzyyisEBgbW7lu7di1XXHEFkydPbppai8gFVT9Q+PPwBHbk1gQKh5iyKIspi7Lo\nFu3P6ORwRiVHEBN0ES2h6OELMX2MUsPphOMHGk7imPsD7FgKjsrqk0zgH2MMiwhOgKD2xvugDuAT\nrmERIiIiItIiNRoipKWlMXDgQABSUlLIzMysPeZwONi7dy+PPfYYeXl5jB8/nvHjx5OZmcnmzZu5\n8cYbCQwM5NFHHyU0NLTpnkJELqj2oT7cM9SHe4Z2YE9eMYszjR4K0xZvYdriLXRu48voLhGMSg4n\nLsTe3NW98Ewm8IsySsLldfsryyBvuzGZY952yNsGR7bD3rVQUVJ3ns3HmATy5IAhMB5sF1FAIyIi\nIiItjsnpdDrPdMIjjzzCiBEjGDx4MABDhgxh6dKlWCwWioqKmDdvHrfeeitVVVXcfPPNTJ06lf37\n9+Pl5UX//v355JNPWLp0Kc8991yD+6alpeHl1fr+GC4tLcXDQ12QxfWcj7adU1TBmr3FrN5bTNbh\nMgBi/a30i/amb4wXCUHumPQv7D/ldGA5cRjb8b24F+7DdnwPtsJ9uBfuw1pyqMGpFV7hlPnEUO4T\nQ7lvW+O9byyVnqHqvXAa+r0trkptW1yV2ra4qtbUtktKSkhNTT3lsUZ7ItjtdoqLi2u3HQ4HFotx\nmaenJzfffDOensZY6L59+7JlyxaGDRtWu2/48OE/CRBqJCYm/rwnaQGysrJaZb1FGnM+2nYiMKSX\n8f7HYyf4LPMQn/+Qw/ub83n3+6OE+3owPCmMEZ3D6NMuCJvF7dwr7urKS4wJHfO2w5EdWPO2Yc3b\nDvuWQHlR3XlWr+plLKt7LwR3MHowBLUH94uwN0g9+r0trkptW1yV2ra4qtbUttPS0k57rNEQoUeP\nHixfvpzRo0eTkZFRO1kiwJ49e/jzn//MggULcDgcbNy4kWuuuYZHH32UESNGMHr0aL7++ms6d+58\nfp5ERFqNCD9PJg1ox6QB7ThaUs6XW3L5fHMOH6Tt5411e/HxsHBpx1BGdA5jcEIIPh7W5q5yy2Tz\ngvAuRqnP6YTCQ8ZwiOqAgbxtcCANNi8A6nUy82kDwe2rh0Z0MN4HdTAmfHRTkCMiIiIiZ6/REGH4\n8OGsWbOGiRMn4nQ6mTp1KnPnziUmJoahQ4cyduxYrrvuOqxWK1dddRUdOnTgvvvu4+GHH+add97B\n09OTKVOmXIhnEZEWyt/LxrgeUYzrEUVpRRVrduTx+eYclmbl8Mmmg9jMbvRvH8SIpHCGJYUS6tM6\nunk1K5MJfCOM0m5Qw2MVpZC/66cBw3fvQ9mxuvMsHsY8C/UDhoC2EBAL9jANjxARERGRn2h0ToSm\nkpaWdtoxFi1Za+qCIvJzNEfbrnI42bivgM83G8Me9h4pwWSClGh/RiSFM6JzGPEX48SMTcXphOLD\n1cHCSQFDwV5wVtWda/EwVo/wjwH/WCNYqP/qGdBqQgb93hZXpbYtrkptW1xVa2rbZ/q+3mhPBBGR\npmJ2M9GrbSC92gby8OhEtuUU8cUPRqDw5JItPLlkC3Eh3gztFMplncLo2TYAq1nd738xkwnsoUZp\nO6DhscpyKNhthAlHq0vN+/0boPRow/PdfU8TMFTvu8jnYRARERFxVQoRRKRFMJlMdAz3oWO4D3+4\nrAMHj57gix+MIQ+vr93Ly6t24+NhYXBCCEMTQxmcEEqgt625q+06LDYI6WiUUyk9Vh0q7GsYMOTv\ngl3LGy5RCeAV1DBg8I+pft8W/KPB4t7kjyQiIiIi559CBBFpkdr4e3JL/7bc0r8txWWVrN6Rx5dZ\nuXy5NZf/fvcjbiboERPApZ1CGZoYSscwHy0f2ZQ8/CCiq1FO5nRCyZHqYGFPXcBQsBd+/A62LIKq\n8noXmMAnol6wcFJvBp82YNb/nkRERERaIv2VJiItnre7hcs7h3N553AcDieZB4+xLCuXL7fk8tRn\nW3nqs61E+ntyWadQLksMpV9cEB5Wc3NX++JhMoF3sFGiTjF2zuGAwh/r9WCo15th71r4/n1wOurO\nd7OAb+RJAUPbutBBkz6KiIiINBuFCCLSqri5mega5U/XKH/+PDyBnOOlLN+Sy7ItubXLR3pazQxo\nH8zQxFAu7RhKuJ9We2hWbm7gF2mU2P4/PV5VAceyjXCh4KT5GLZ9BsW5Dc+vnfQx1rinb01pA35R\nxqvN+8I8m4iIiMhFRiGCiLRqYb4eTOwdw8TeMZRWVLFu1xGWb8llaVYuS7NyAEiM8GVwQgiDE0JI\njQ3AZtHkjC2K2QqBcUY5lfISI2SoDRj21PVm+DHDWHHiZB7+RrDgF0l4lRfkJleHDJHgWxM0eDXp\nY4mIiIi4IoUIIuIyPKxmhnQMZUjHUJ640sn23CKWZeWyYlsur6zaxYsrdmJ3t9A/PojBHY1QISpA\nXyRbPJvXmSd9rCiFwoNw/CAcOwDHa8pBOLYfn4J9sGvhT6/zDKgLFPyqezL4RhnvfSKMYRPuPho6\nISIiIlKPQgQRcUkmk4mEMB8Swny4e0g8haUVfL3zCCu2HearrYf5/Aejl0J8iDeDE0IZ3DGEPu0C\nNZdCa2T1OGNPhu1ZWSS2b/eTcIHjB+v27f8WTuSf4t7e4BNeV+w17yPAJ0xhg4iIiFx0FCKIyEXB\nx8PKiM7hjOgcjtPpZOfhYlZsO8yKbYd5c/1eXluzGw+rG33jgmqHPrQL9taKD67C6gFB8UY5nfIS\nYwLIY/uhKMd4X1jzeggOphuvJy9nCdVhQ3Wo0CBsqBc6KGwQERERF6AQQUQuOiaTifahdtqH2rnt\nknacKK9i/e4jfLX1MCu3Heb/Pv0BgOhATwYnhDCoQwj94oPw8bA2c82lSdm8Gg8anE4oKzTChKJD\nxmv9sKEo59zCBnu4cdzdV2GDiIiItEgKEUTkoudpq5tLAWDfkRJWbD/Miq2H+WjjAd5ctw+zm4mU\naH8uaR/MJR2CSYn2x2rWBI0XHZMJPHyNEpJw+vNOGTbUCx0aCxssnkaYUBMq2KtLTdBgDwHvUGNZ\nTbPCLREREblwFCKIiJwkJsiLm4JiualvLGWVVWzce5Q1O/JYtSOP57/czr+XbcfubqFvXCAD2gcz\nsEMw8SF2DX2QOucaNhTlVA+pOAS5WbDzKyg7dup7eAaCPRS8Q4xS894eagQNNYGDPRQs7k3yuCIi\nInLxUIggInIG7hYz/eKD6BcfxP2Xd+RYSQVf78pj1fY8Vu/IY2lWLgDhvh61gUL/9kGE+ng0c82l\nVTjbsAGg4kR1sJADxblQlGssb1mUW7192FjysugwlBee+h7ufkaoYA+rCx28g43iVf3qHWK89wwA\nN/W2ERERkYYUIoiI/Ax+XlZGJkcwMjkCgOz8ElbvyGP19jyWbcnhw437AegU7lM79KF3u0C8bPp1\nK+fI6gkBbY3SmPISI2A4OWSoHz7kZBqvpafp4WByA6+geuFCTdAQAt5B9d5Xv3r4K3QQERG5COiv\nWhGRcxAd6MX1vWO4vncMVQ4nPxw8zqodh1m9PY95X+/lldW7sZpNdI8OqO3R0D3GH3eLlpKUJmTz\nAlssBMQ2fm5VBZQcgeI8KMkzXhu8P2wcP1QTOhw99X1MZvAKbBgs1O/tUD+Q8ApS6CAiItJKKUQQ\nETlPzG4mukT50SXKj98Nac+J8iq+3ZPP6h15fL3zCM9Vz6fgbnGjZ9sA+sUF0S8+mK5RfpqkUZqP\n2Vq3OsTZqKqAkvzqcOHk0OFw3fbBDGO77Pip72NyM+ZzqOnh4BXYMGzwCqrr8eAVZBzTnA4iIiLN\nrtEQweFw8MQTT7B161ZsNhtTpkwhNrbuXzamTJnCxo0b8fb2BmDWrFlUVFRw//33U1paSmhoKNOm\nTcPT07PpnkJEpAXytJkZlBDCoIQQAI6dqOCb3fms3WmECk9/vg3YhpfNTK+2gfSv7qnQuY0fZjdN\n0igtlNlavUxl2NmdX1Fq9GQoyavu8XDkpO3q17xtsHctnMgHp+PU97LZ6wKF2rChfhARVF0CjYDC\n0x/c1OtHRETkfGo0RFi6dCnl5eXMnz+fjIwMpk+fzuzZs2uPb968mVdeeYXAwMDafVOmTOGKK65g\n3LhxzJkzh/nz5zNp0qQmeQARkdbCz9PK8KQwhicZX76OFJWxfnc+X+88wtqdeUxbfBgAHw8LfdoZ\ngUK/uCA6hfvgplBBWiurB/hFGuVsOBzGkImacKFB2JBf1/uhKNdYuaLkyKmXyQTABB5+1aFCgBEs\n1AQMNfsabFfvs3kbk16KiIjITzQaIqSlpTFw4EAAUlJSyMzMrD3mcDjYu3cvjz32GHl5eYwfP57x\n48eTlpbGnXfeCcCgQYOYMWOGQgQRkZME2d0Z3SWC0V2MSRpzj5fy9a4jfL3zCF/vOsLSrBwAArys\n9GkXRO92gfSJC6RTuK96KojrcnMzvtB7BTZ+bo3ykoaBQ0mB0aOhJL/ha/FhyNsKJ46efpgFgNl2\nUuAQ8NOgwTPA6Ong4V/33uql8EFERFxeoyFCUVERdru9dttsNlNZWYnFYqGkpIQbb7yRW2+9laqq\nKm6++WaSk5MpKirCx8cHAG9vbwoLT73UVFZW1nl6jAuntLS0VdZbpDFq2y1DgjskJFm5JSmc3KJK\nNh06wXeHTpC+N48lmw8B4G11o3OYB8nVpUOQOxaFCqeltn0x8QAiwRoJVsD3DKc6KjGXH8Ncdrz6\n9ViDV0vZMczlxzGXHMNccKD2mMlZddpbOt0sVFl9qLL5UmXzwVH9WrPPYfMxtm2+xra1bttpdv/Z\nAYTatrgqtW1xVa7SthsNEex2O8XFxbXbDocDi8W4zNPTk5tvvrl2voO+ffuyZcuW2ms8PDwoLi7G\n1/fU/xdPTEw8H89wQWVlZbXKeos0Rm275UkEBtfbPnD0BN/uzmf97ny+2X2E19LyAfC0mukR60/v\ntkZvhe4x/nhYNQ68htq2nDdOJ5QXVfdsKDCGXZw4WvtqOlGApfQolnr7OH6w+pxjgPP09zbbGvZq\ncPc1hmJ4VL/WbvsZ53n4sfN4HvHtexj7rB4X7Mcg0tT0e1tcVWtq22lpaac91miI0KNHD5YvX87o\n0aPJyMggISGh9tiePXv485//zIIFC3A4HGzcuJFrrrmGHj16sGLFCsaNG8fKlStJTU09P08iInIR\ni/T3JLJ7JFd3N8aWHy4sY8MeI1RYvzuffy3bhtMJVrOJblH+9G4XSO92gfRsG4jdXYvxiJwzkwnc\nfYxyNstn1udwQNmxBqFD7espAglK8iB/J5QeNwIIR8VPbhkPsLh6w+xeL2SoFz7UFHff6lJdf4+a\n9/VeLT+/N4SIiFx8Gv2rcvjw4axZs4aJEyfidDqZOnUqc+fOJSYmhqFDhzJ27Fiuu+46rFYrV111\nFR06dODuu+/mwQcf5L333iMgIIBnnnnmQjyLiMhFJcTHnVFdIhhVPafCsZIKNuzN55vqUOGllbuY\n9dVO3EyQHOlHr7ZGqJAaG0CwXUvliVxQbm51cyn8XE4nVJww5nEoPVZbDuz8gcgge4N9DcrR7Lr3\nVWVnUUfr6QOGmvDB3ac6lPA5qVSfY7OD1VNhhIiICzM5nc4z9K1rOmlpaa2yh0Jr6oIi8nOobbue\n4rJK0vcd5ZvdR1i/O5/07KOUVxpL57UL9iY1NoDU2AB6xgYQH2J32RUg1LbFVf2stl1ZBmVFRm+I\nssK6UnrcCCdq9x0/6fixhseqyhv/LJMZ3O1g86l+tde91n9/ynPqb1eHEhbbuf2gpNXR721xVa2p\nbZ/p+7r6t4qIuChvdwuXdAjmkg7BAJRVVvH9/mNs2FvAhj0FfLkllw/S9gPG8pP1Q4Vu0ZpXQcSl\nWNyN4h10bvepLGsYNtSGEEVQXi98KCsy5o8oK6x+LTKW5aw9r+iUQzROyWw7y9DhpPDhdMfd9LtN\nRORcKEQQEblIuFvM9GxrzJHAYHA6nezKKyZtbwFpewrYsDefL7fkAmBxM9E50o+e1aFCatsAQn00\ncZvIRa82jAg+93vV9I4orx86nOX2iQI4ll23v7wInI6z+1yr16lDB5sXWDyNSSqtXmDxaPje5m0M\n1bBWv9q8jGP192koh4hcBBQiiIhcpEwmE/EhduJD7FzXMxqAguJyI1TYZwQLb67by6urdwMQE+hV\n11uhbQAdQn0wu+gQCBG5AM5X7wionjei5NQ9IM5mu/BHY96JylLjPhWlUHni7IOJ+qxe9Ur9sKFm\nuyZwOMO+BgHFSfvM1nP/eYmInAOFCCIiUivA28awpDCGJYUBUF7pIPPgsdqeCqu2H2ZB+gEA7O4W\nukX70T06gJRof1Ji/DVho4g0D5PJ+CJu8wbCzs89nU5jDoiKE9WlpN5rCZSXnGFf9f7y4rrrS/Kq\n99U/p+Tn18vNWi9U8DR6T1jcjd4SFvfqfTXbHqfZ797wOqvHqffXP6ZhICJSTSGCiIicls3iRo+Y\nAHrEBPBb4nA6nezLL2HDngIyso+Snl3A7BU7qXIYc/TGBHrRPcaflGh/uscEkBThi83i1sxPISLy\nC5hMdb0lPP2b5jOcTqP3w8nBQvlJ4USDfcUNA4rK0upSZvSqKM6r2649Vnp2k2KeiZvlDMHDmQKL\nk847ZWDhbixTaraC2Ya1MBuO+RjzYZit1cdsRpCh4SIizU4hgoiInDWTyURskDexQd5cmxoFwIny\nKjIPHiN9XwHp+46yflc+H2ccBIwQIrmNLynRAXSP8ad7jD+R/p6Y9EegiIjxhbhmLgXOw7COM3E4\nGgYOlSfqBQ1l1YHEScHDT/afdF1FvfNKj0FlzqmvO9tJNKu1B/jfqY6YjDDBUhc4NCzW6mP1w4d6\n51lOPt9Wd7zBPU93Xb1Ao/51bmajh4jZary6KTwX16YQQUREzomnzUyvtoH0ahtYu+/HYyfI2HeU\n9OyjZOw7ytvf7OW1NcbcCiE+7tU9FfzpHh1A1yg/vN31vyMRkSbl5mYMgbB5XfjPdlQ17B3xk8Ci\nDKoqjN4SVWUcyN5LZFjwSfsroKqs7n1lvfdV5Q1LZfUwlAbXVZ9X/54/M9w4aya3eqGCpS5cMFsa\n9sow24zjDYr57Lbr39vsXtej4+TzTObG71W/N0jt/pOvVy8QqaO/2kRE5LyL8PMkoosno7pEAFBR\n5WDroUKjt0J1sPDFDzmA8TdJ+xA7XaP86RrlR9coPxIjfLXEpIiIq3Az15uzonHHzVlEJiY2caWo\nm/fitMHEacKHkwMLRwU4Ko3jta8VUFVZ/Vpvu6qsXoBSfV9HsXGdo6r6tfI02yeVXzLx5zkxnSKg\ncKsLJRr01LDUO8dc91r7viaYcKsXblgb9vCoOdbgHm7G/pPva6quR/0eJrWfUXPcrd770+yv+fya\ne9Xc++TSYH91wHIRhSwKEUREpMlZzW4kR/qRHOnHTf2MfQXF5WTsP8p32cf4bv9RVmw7zIcb9wPG\nEpMdw33oGuVPtyg/ukb50yHMjtWsLqIiInKe1J/3ojVyOOrCjsrq4qw6Tfhw8v7q97VhSJlxn9pz\nqqrvVWl8jqOy3naVEWCcHHQ0CFkqfnp+ZWm9+1ad9L76vJreJpXldcecVc0QmPwSJiNcMNvqep4M\nuNcoLkYhgoiINIsAbxuXdgz9/+3deWxU590v8O85Z/Yzm8fjHW8YDA4EeAlN79ULvq0ozdK3TVtF\nDaglkdIGqWpoI6WEkiaUJpRFaaMoJJCmanIlkjbcllyam7xv8l4qAhfSbH7rpKZmC7ttxvt49u2c\n+8cZH89gO+MQYzPD9yONzm6fEz0Zz3z5Pc+DL88pBQCoqooufxQfXxzExxf9+PiiH2983Ik/vn8e\nAGA2iJhX6dSChWoXbmuE/2YAAB4kSURBVKxyY6ZXhshpJomI6HokioCYHqyy0KlqOrjICB5UJb2u\njAQWqUR2dxUllb728muG15XL9l8WhqiKdn3m+WrmtUr2fiU1Un2SigMVC6f7v9xVwRCBiIiuCYIg\noNJtRaXbilvna90gVFXF2b5wRrAwiD0fXMD/fOcsAMBhNmB+lQsLql1YUKV1h5hRxIEbiYiICoog\njHRdoGnHEIGIiK5ZgiCg3iuj3ivjjkVVAIBkSsGpnqAeKnx80Y8XDp9BIqVNM1lkM2J+lQvzKl2Y\nX+WENZLAHEVlxQIRERHRJGCIQEREecUgiZhb7sTccie+s6QaABBLpnCsK4CPLw6irWMIbZ1+/P7w\naT1YcPx7F26odKbDBW050yvDwDEWiIiIiD4ThghERJT3zAYJC6vdWFjt1vfFkimc9AXxfz88hn5V\nRlunHy+/dw7RhDY4k8UooqnCifnpioV5lS40ljlgMjBYICIiIhoPQwQiIipIZoOE+VUuSENONKWn\nCkumFJzuDaGtw69XLPzvv3dg97vnAABGSZsVYn6lVrEwr8qFpnInrCb2wSQiIiICGCIQEdF1xCCJ\naCxzoLHMgW8v1vYpiorz/WG0dWrBwtFOP946egmvfHABACAKQJ1XRlOFEzdUONFU4UBThRPlTgsH\ncCQiIqLrTs4QQVEUbNq0CcePH4fJZMLmzZtRW1s76pw1a9Zg+fLlWLVqFVRVRXNzM+rq6gAAixYt\nwoMPPnhVHoCIiOjzEEUBdV4ZdV4Z/7agEoA2K0SnP4qjHX4c7RxCe9cQPr44iDc+7tKvK7IZMbfc\niaaMYGF2mR1mA6sWiIiIqHDlDBH279+PeDyOPXv2oLW1Fdu2bcOuXbuyznnqqafg9/v17fPnz2Pe\nvHl47rnnJv+OiYiIrjJBEFDltqLKbcVX55Xr+4eiCRzrCqC9a0h//eH9kXEWDKKAhhK7HioMv0oc\n5ul6FCIiIqJJlTNEaGlpwbJlywBoFQVtbW1Zx998800IgoDm5mZ939GjR+Hz+bB69WpYLBZs2LAB\nM2fOnORbJyIimlpOixE313twc71H35dSVJzpDWUFC++e7se+1k79HK/djKYKR7o7hPaaWSLDyNkh\niIiIKM/kDBGCwSDsdru+LUkSkskkDAYDTpw4gddffx1PP/00nn32Wf2ckpISrFmzBrfddhs+/PBD\nrFu3Dnv37r06T0BERDSNJFHArFI7ZpXa8fWFlfr+/lAcx7qG8M/0q70rgBeOnNGnnTRJImaWyJhb\n7kBjuUNbljlQ5bZyrAUiIiK6ZuUMEex2O0KhkL6tKAoMBu2yffv2wefz4Z577kFHRweMRiOqqqrw\nhS98AZKk9QldsmQJfD4fVFUd9aGovb19Mp9lSkSj0by8b6Jc2LapUE1n2y4C8K9e4F+9ZuBGMxKp\nYlz0x3F6II6zA3GcHYzj8AlfVtWC1Sigzm1CrduEuiKTtl5kgtvCsRYoG9+3qVCxbVOhKpS2nTNE\nWLx4MQ4cOIDbb78dra2taGxs1I899NBD+vqOHTvg9XrR3NyMJ554Am63G/fddx+OHTuGysrKMf9V\nZXjKrXzS3t6el/dNlAvbNhWqa61tLxhjnz+SwElfAMcuBXDCF8DxSwG82xHAmycD+jleuxlzyu1o\nLBupWmgsc0A2c6Kl69W11raJJgvbNhWqfGrbLS0t4x7L+cljxYoVOHLkCFauXAlVVbFlyxa8+OKL\nqKmpwfLly8e8Zs2aNVi3bh0OHjwISZKwdevWK797IiKiAueyGrGkzoMldSNjLaiqip5ADMfTocLx\ndMDwyvsXEEmk9POqPVbMKXNgTjpYmFPuQL1X5iwRREREdFXkDBFEUcRjjz2Wta+hoWHUeWvXrtXX\nXS4Xnn/++Um4PSIiouuTIAgodVpQ6rRg2ewSfb+iqLgwENZDheHqhbeP9yCpaOMtiAJQWyxjVqkd\ns0vtmF1mx6wSBxpKZdhMrFwgIiKiK8dPEkRERHlEFAXUFsuoLZazpp+MJxWc7g3ipC+Ik91BnOoO\n4KQviLePd+uDOQLAjCIrZqcHgpxd6sCsMm3daTFOx+MQERFRnmGIQEREVABMBhFzy52YW+7M2p9I\nKTjXF9ZDBS1gCOKdT/oQSyr6eWVOsxYq6AGDHbPLHPDIpql+FCIiIrqGMUQgIiIqYEZJ1IOBW+eP\n7E8pKi4OhHHSF8SpHq2C4VR3AP/rwwsIx0fGXCiWTWgYDhVK7WgotaOhxI5ypwWiyKkoiYiIrjcM\nEYiIiK5DUka3iK+gTN+vqiq6/FGc7A7ipC+AU91a9cL/+agTQ9Gkfp7VKKHeK2NmiYyGEru+rPfK\nnDGCiIiogPGvPBEREekEQUCl24pKtxX/o3FkQMfh2SI+6QnhdG8Qn3Rry48v+vHGP7qgjgy7gAqX\nBTNLZMz02tFQImNmOmSodFlZvUBERJTnGCIQERFRTpmzRfz3huKsY9FECuf6wjjdE8QnPUGc7gnh\nk94Q9v29A4HYSPWCxSii3puuWvDKaCi1Y6bXjvoSGXZWLxAREeUF/sUmIiKiz8VilDCn3IE55Y6s\n/aqqoicYw+mekBYs9ARxuieItg4//uMfXVAyqhfKnGY9UKgvllHnlVHvtaHaY4PZIE3xExEREdF4\nGCIQERHRVSEIAkodFpQ6LPhvM7OrF2LJzOqFkF7B8O//6MJgOKGfJwpApduKeq+Muoxwoa5Yxowi\nG0wGcaofi4iI6LrGEIGIiIimnNkgobHMgcYyx6hjg+E4zvSGcLYvhDO9YZxNr+9r7UAgY3BHSRRQ\n5bZqwUKxDXXedMhQLGNGkRUGiQEDERHRZGOIQERERNcUt82Ef6kx4V9qirL2q6qK/lA8K1w40xfC\n2d4QWs72I5QxNaVBFFDtsaEuHS4MVzLUe2VUuq2QOMAjERHRFWGIQERERHlBEAQU280otptxU60n\n69jw+AtnMyoXhsOGd0/3I5IYCRiMkoAZRTbUeLRXbfHwUka1xwqbiR+PiIiIxsO/kkRERJT3Msdf\nuLl+dMDQHYhpXSR6QzjbF8b5/hDO9YXxX+cGsmaQAIAShxm16YChpng4ZJBR47HBazdBEFjFQERE\n1y+GCERERFTQBEFAmdOCMufoAR5VVcVgOIFz/WGc7w/jfJ8WLpzrD+Nvp/vw6t87ss6XTRKqMysY\nimU9cKgqssLIcRiIiKjAMUQgIiKi65YgCCiSTSiSTVhU7R51PJpI4eKAFjCc69NeF/rDON0bwtsn\nehBPKvq5kiig0m1Jd5PQKhdmFFlR7bGhusgKj8wqBiIiyn8MEYiIiIjGYTFKmFXqwKzS0bNIKIrW\nTeJcX0irZOhLhw39YbzZ1oWBjKkqAcBmkrRQociG6nTAMKPIhmqPtnRZjVP1WERERFeMIQIRERHR\nFRBFAeUuC8pdFnzxsm4SABCIJnBxIIKLAxFc6A/jwkBYX3/vTD+Cl43F4LQY9HAhM2gYXnLARyIi\nuhbwrxERERHRVeCwGNFUYURThXPUMVVV4Y8kcKE/kg4Xwvr6Jz0hHDzRg2hCybqmWDZhRrprxIwi\nG4yxIfRIPagqsqLSZYXVJE3VoxER0XUsZ4igKAo2bdqE48ePw2QyYfPmzaitrR11zpo1a7B8+XKs\nWrUK0WgU69atQ19fH2RZxvbt2+HxeMb5DURERETXF0EQ4LaZ4LaZcOMM16jjw1NWDlcuaBUNWtDw\njw4/3jp6CYmUCrzbq19TLJv0QKGqyIoqtxWVbitmpNfdNiPHZCAios8tZ4iwf/9+xONx7NmzB62t\nrdi2bRt27dqVdc5TTz0Fv9+vb//xj39EY2Mj1q5dizfeeAM7d+7EI488Mvl3T0RERFSAMqesXFxT\nNOp4SlFx5L/aYPZUotMfQcdABB2DEXQMRnGyO4C3T3SPqmSwmSRUurVAYThkGF6vdFtR5jDDwNkl\niIgoh5whQktLC5YtWwYAWLRoEdra2rKOv/nmmxAEAc3NzVnX/OAHPwAANDc3Y+fOnZN5z0RERETX\nNUkUUCIb0DTGWAyAVskwEE6kwwWtkqFzMIqOwTA6BrVqhv5QfNTPLHdaskKGyssCB3aZICKinCFC\nMBiE3W7XtyVJQjKZhMFgwIkTJ/D666/j6aefxrPPPpt1jcOhjWIsyzICgcCYP7u9vf3z3v+Ui0aj\neXnfRLmwbVOhYtumQjWRtm0AUCsBtV4AXgGAnH4B0YSC7lASPaEkfKEkuoNJbTsYxpGeIfSGk1DU\n7J/nNIsokQ0olQ3wXrYskQ3wWCVIIrtM0OfD920qVIXStnOGCHa7HaFQSN9WFAUGg3bZvn374PP5\ncM8996CjowNGoxFVVVVZ14RCITidowcUAoCmpqbJeIYp1d7enpf3TZQL2zYVKrZtKlRXu20nUwp8\ngZhezdAxEEGnP4rOwQi6BqNo6w4jcNkME5IooMxhRqXbigq3FZUui7aeXla6rSji2AyUA9+3qVDl\nU9tuaWkZ91jOEGHx4sU4cOAAbr/9drS2tqKxsVE/9tBDD+nrO3bsgNfrRXNzM06dOoWDBw9iwYIF\nOHToEG666abP+QhERERENJUMkqh3YwDGHiB7KJpA12AUnf6IHi50DkbQ6Y/gowuDeKstingqe2wG\ni1FEpct6WbgwHDZo65zOkojo2pXzHXrFihU4cuQIVq5cCVVVsWXLFrz44ouoqanB8uXLx7xm1apV\nWL9+PVatWgWj0Yjf/OY3k37jRERERDS9nBYjnOVGzCl3jHlcUVT0hmIZ4UK6ksGvDQJ54kQPeoIx\nqJd1m3DbjOmgITtcGK5m4CCQRETTJ2eIIIoiHnvssax9DQ0No85bu3atvm61WvH0009Pwu0RERER\nUb4SxZFZJhZWu8c8J55U4BuKoiMdLnQODgcNUVwciOD9M/0YimZ3mxAFoMxpyeomUemyoCJdOVHh\nssAjm9htgojoKmCtGBERERFNG5NBRLXHhmqPbdxzgrEkugYj6aAhXdWQDhvaOvz4z3/6EE9md5sw\nG0S9q0SFayRoyNwnm/lRmIjos+I7JxERERFd0+xmA2aXOTC7bOxuE6qqoi8UzwoX9KoGfwT/72QP\nugOju024rEZUuLRpLSuGu0tkjNdQ7rLAyG4TRERZGCIQERERUV4TBAFeuxleuxkLZox9TiKl4JI/\nOlLJ4I9kjdXw4bkB+COJy34uUJqebWJ4jAa9qiEdOhSz2wQRXWcYIhARERFRwTNKubtNhGLJrHEZ\nMgeC/GfXEPa3+xC7rNuEySBq4zFcFi6MVDhYYWe3CSIqIHxHIyIiIiICIJsNmFXqwKzS8btN9Ifi\n6PKnB4LMCBo6ByN455Ne+IaiUC7rNuGwGFDhsqDMaUG5U+smcfl6sWyCKLKigYiufQwRiIiIiIgm\nQBAEFNvNKLabMb/KNeY5yZQCXyCmBwudg1F0+SO45I/CNxTFCV8APYHYqKDBKGkzWZQ5zWOGDMPr\nFqM0BU9KRDQ+hghERERERJPEIImoSk81OZ5kSkFvMI5LQ1E9XLg0pC19Q1EcvxTAoRO9CMaSo651\nWY0od1pQ5rKg3GlGudOCUqcWNJSlt4vtZkisaiCiq4QhAhERERHRFDJIIsrTsz+gevzzgrHkSMjg\nj+qhw3DgcKxrCL3B0VUNogCUOMwoc1pGqhvSQUOp05wOHCwoshk5KCQRfWYMEYiIiIiIrkF2swGz\nSu2YVWof95xkSkFfKK4HDb5ADN16VUMMFwfCaDnXj4FwYtS1JklMhw0jwUKJw4xShxmlTou2dJhR\nZON4DUQ0giECEREREVGeMkiiHgCMN70lAMSSKXQPxeAbiqI7ENNDhu6hKHyBKE52B3H4ZC8CY3Sh\nMIjaFJqlTi1UKHFkhA0ZgUOJwwyjJF7FpyWiawFDBCIiIiKiAmc2SDmnuASASDyF7kAUPYEYutNV\nDd3p9Z5ADB2DUbReGERfKA5VHX19sWzK6Eph1rtQDIcNJXYzvHYzrCYOEEmUrxgiEBERERERAMBq\nklBbLKO2WP7U8xIpBX3BeDpsSFc1BNKBQ3r9+KUAeoIxpC4ftAFaVw2v3QRvOlTwOkwosVvgdZgQ\nHQwhbBtAiV2rbmDgQHRtYYhARERERESfiTFzcEiMPd0lAKQUFf3pMRt6AjH0BLWKht5gDL3BOHoD\nMZzqCeLdMzEMZo7bcMCnr9rNBpQ6zPA6zHq3idKMLhUlHLuBaEoxRCAiIiIioqtCEgWUpL/o5xJP\nKugPxfH+P47B4a3UA4fMV1uHHz2BGELx1Ji/y2s3jYQM6UqG4ZDB6zDr+2QzvwYRXSn+30NERERE\nRNPOZNCqG2YXm9E0t/RTzw3FkiPjNgSi6M2ochgeOLKtwz/mFJgAYDNJ8A6HDBndKUocZj2I0NbN\nsBjZnYIoE0MEIiIiIiLKK7LZANlsQJ3308duSCkqBsJxdA9pXSiGu1Rkhg6ne4N470xszGkwAcBh\nMWSEDSPVDJmVDiUOMzyyibNT0HUhZ4igKAo2bdqE48ePw2QyYfPmzaitrdWPv/zyy3j11VchCAJ+\n9KMf4ctf/jJUVUVzczPq6uoAAIsWLcKDDz541R6CiIiIiIjoclJ6ekqvfWLdKfpCMfQG4ugJRtNj\nN8SzulO0dw7hUCA25lSYAOCRTRmVDSPVDF67GcXpgSSL7SYUy2aYDAwcKD/lDBH279+PeDyOPXv2\noLW1Fdu2bcOuXbsAAP39/fjDH/6Affv2IRaL4Wtf+xq+9KUv4fz585g3bx6ee+65q/4ARERERERE\nn5fJIKLCZUWFy4pPGywS0KbC7A3GssZt6M0cwyEYQ8v5AXQPxRBLKmP+DKfFkBUqFNtNKLZr3SmK\n5fQyve20GDloJF0zcoYILS0tWLZsGQCtoqCtrU0/5vF48Je//AUGgwEdHR1wOp0QBAFHjx6Fz+fD\n6tWrYbFYsGHDBsycOfPqPQUREREREdEUsZokVHtsqPbYPvU8VVURjCXRF4xrVQ7BuLYejKEvFEdP\nMIa+YAyf9ATx/tk4BsJxqGOM4WAQBXjkzJBhuKphuMJhJIjgOA50teUMEYLBIOx2u74tSRKSySQM\nBu1Sg8GAl156CTt27MDq1asBACUlJVizZg1uu+02fPjhh1i3bh327t076me3t7dP1nNMmWg0mpf3\nTZQL2zYVKrZtKlRs21SoCrVt2wDUiECNE4ATAEQA1vRLk1JUDMVSGIwqGIym4I+kMBjVXv5oCgOR\nJLoHYjjZpe2LJsdIHABYDQJcFglFVgluiwSXRVu6rRKcZgkui5heausmjuUwJQqlbecMEex2O0Kh\nkL6tKIoeIAz73ve+h+985zu477778O6772LhwoWQJC39WrJkCXw+H1RVhSBkl+A0NTVNxjNMqfb2\n9ry8b6Jc2LapULFtU6Fi26ZCxbY9ceH4cJVDurohGEdvKL0MjixPDcbRH4ojNdZUFQBkk4QiWatw\nKJJN8MgmeGwmeOzppZz9YveKK5NPbbulpWXcYzlDhMWLF+PAgQO4/fbb0draisbGRv3Y6dOn8eST\nT2LHjh0wGo0wmUwQRRHPPPMM3G437rvvPhw7dgyVlZWjAgQiIiIiIiK6cjaTATaPIWe3CgBQFBX+\nSAJ9Ia3bRF9QW/aHsl99wThO+oLoD8URSaTG/FmSKKDIZoRHNqHIZkKxPb3MDCEyXkU2E7tYFJCc\nIcKKFStw5MgRrFy5EqqqYsuWLXjxxRdRU1OD5cuXY+7cubjrrrsgCAKWLVuGm2++GXPmzMG6detw\n8OBBSJKErVu3TsWzEBERERER0RhEUUBR+kv+REXiKfSH4xgIadUOYy37Q3GcSIcO443pAOSudihK\nhw1FNiNcNiOKbJwy81qVM0QQRRGPPfZY1r6GhgZ9/f7778f999+fddzlcuH555+fpFskIiIiIiKi\nqWY1SagyWVHltuY+GdqYDv5IYlR1Q2blQ98Eqx0AwG42wJ0OFDKX7nTYkLm/yGaCy2aE02JgFfxV\nljNEICIiIiIiIspFSs8i4fmM1Q59oRgGwwkMhOMYCCfgTy8HwvGs/ef7wxgMJ+CPJD71HtxWY0bo\noAUOI+HD8LYJRbJ2jstqZHeLz4AhAhEREREREU0Lq0nCDJMNM4omfs1wxYMWMsQxENLWh/cNhBP6\n/osDYRzt1PZHE8r492GUssIFPXywZlQ7yNlBxPU6wCRDBCIiIiIiIsobV1LxAADRREoLGULpkCGc\nwGAkXe0QyggfwnF0DQ5hMKJtjzOpBQQBcFlHqhncNmO6CmJku8hmwoobyiCbC+erd+E8CRERERER\nEdE4LEYJFS4rKlwTG+MB0Ga1CEST6QoHLXAYjGQHEcNVEP2hOE73hDAYjmMomtR/xsZ/uwH3Lq2/\nGo80LRgiEBEREREREY1BFAW40jNG1EGe8HUpRcVQJIFANIlqz8RDi3zAEIGIiIiIiIhoEklXMKVm\nvuDEm0REREREREQ0IQwRiIiIiIiIiGhCGCIQERERERER0YQwRCAiIiIiIiKiCWGIQEREREREREQT\nwhCBiIiIiIiIiCaEIQIRERERERERTYigqqo6Hb+4paVlOn4tEREREREREeVw0003jbl/2kIEIiIi\nIiIiIsov7M5ARERERERERBPCEIGIiIiIiIiIJsQw3TeQDxRFwaZNm3D8+HGYTCZs3rwZtbW1031b\nRFfko48+wq9//Wvs3r0b586dw89+9jMIgoDZs2fjF7/4BURRxDPPPIO3334bBoMBDz/8MBYsWDDd\nt000rkQigYcffhgdHR2Ix+P44Q9/iFmzZrFtU95LpVJ45JFHcObMGUiShK1bt0JVVbZtKgh9fX34\n9re/jRdeeAEGg4HtmgrGN7/5TTgcDgDAjBkzcNddd+FXv/oVJEnC0qVLcf/99+f990uGCBOwf/9+\nxONx7NmzB62trdi2bRt27do13bdF9Jn97ne/w2uvvQar1QoA2Lp1Kx544AF88YtfxMaNG/HXv/4V\nlZWVeP/99/GnP/0JXV1dWLt2Lfbu3TvNd040vtdeew1utxtPPPEEBgYG8K1vfQtz585l26a8d+DA\nAQDAK6+8gvfee08PEdi2Kd8lEgls3LgRFosFAD+PUOGIxWIAgN27d+v77rjjDuzYsQPV1dVYs2YN\njh49qv/DR75+v2R3hgloaWnBsmXLAACLFi1CW1vbNN8R0ZWpqanBjh079O2jR4/i5ptvBgA0Nzfj\nnXfeQUtLC5YuXQpBEFBZWYlUKoX+/v7pumWinG699Vb85Cc/0bclSWLbpoLwla98BY8//jgAoLOz\nE16vl22bCsL27duxcuVKlJaWAuDnESocx44dQyQSwb333ou7774bH3zwAeLxOGpqaiAIApYuXYq/\n/e1vef/9kiHCBASDQdjtdn1bkiQkk8lpvCOiK3PLLbfAYBgpQFJVFYIgAABkWUYgEBjV3of3E12r\nZFmG3W5HMBjEj3/8YzzwwANs21QwDAYD1q9fj8cffxy33HIL2zblvVdffRUej0f/AgXw8wgVDovF\ngu9///v4/e9/j1/+8pfYsGGDXgEMjN++8+37JUOECbDb7QiFQvq2oihZX8SI8pUojrwFhEIhOJ3O\nUe09FArp/bqIrlVdXV24++67cccdd+DrX/862zYVlO3bt+Ott97Co48+qpfKAmzblJ/27t2Ld955\nB6tXr0Z7ezvWr1+fVWHAdk35rL6+Ht/4xjcgCALq6+vhcDgwODioHx+vfefb90uGCBOwePFiHDp0\nCADQ2tqKxsbGab4joslxww034L333gMAHDp0CEuWLMHixYtx+PBhKIqCzs5OKIoCj8czzXdKNL7e\n3l7ce++9WLduHe68804AbNtUGPbt24ff/va3AACr1QpBEDB//ny2bcprL7/8Ml566SXs3r0bTU1N\n2L59O5qbm9muqSD8+c9/xrZt2wAAPp8PkUgENpsN58+fh6qqOHz4sN6+8/n7Zf7EHdNoxYoVOHLk\nCFauXAlVVbFly5bpviWiSbF+/Xo8+uijePLJJzFz5kzccsstkCQJS5YswV133QVFUbBx48bpvk2i\nT/Xcc89haGgIO3fuxM6dOwEAP//5z7F582a2bcprX/3qV7FhwwZ897vfRTKZxMMPP4yGhga+b1PB\n4ecRKhR33nknNmzYgFWrVkEQBGzZsgWiKOKnP/0pUqkUli5dioULF+LGG2/M6++Xgqqq6nTfBBER\nERERERFd+9idgYiIiIiIiIgmhCECEREREREREU0IQwQiIiIiIiIimhCGCEREREREREQ0IQwRiIiI\niIiIiGhCGCIQERERERER0YQwRCAiIiIiIiKiCWGIQEREREREREQT8v8BuhTT2bYO40gAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(gb_classifier.loss_values, label='train loss')\n",
    "plt.plot(gb_classifier.loss_values_evalset, label='evalset loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке выше вы должны видеть два графика - лосс на обучающей и на валидационной выборках по итерациям бустинга.\n",
    "\n",
    "Проверим, что наш бустинг действительно работает: сравним предсказание типа \"подбрасывание монетки\" с предсказаниями бустинга для обучающей и валидацонной выборок - после 500 итераций ошибка бустинга должна быть как минимум вдвое меньше.\n",
    "\n",
    "*Код в ячейках ниже должен выполняться без ошибок.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy для случайного предсказания: 0.425\n",
      "Accuracy для предсказаний бустинга: 0.912\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_random = np.random.binomial(1, 0.5, size=len(y_train))\n",
    "accuracy_baseline = accuracy_score(y_train, y_random)\n",
    "print('Accuracy для случайного предсказания: {:.3f}'.format(accuracy_baseline))\n",
    "\n",
    "y_pred = np.array(gb_classifier.predict(X_train) > 0.5, dtype=np.int)\n",
    "accuracy_boosting = accuracy_score(y_train, y_pred)\n",
    "print('Accuracy для предсказаний бустинга: {:.3f}'.format(accuracy_boosting))\n",
    "\n",
    "np.testing.assert_array_less(1 - accuracy_boosting, (1 - accuracy_baseline) / 2 + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy для случайного предсказания: 0.550\n",
      "Accuracy для предсказаний бустинга: 0.800\n"
     ]
    }
   ],
   "source": [
    "# Val\n",
    "y_random = np.random.binomial(1, 0.5, size=len(y_val))\n",
    "accuracy_baseline = accuracy_score(y_val, y_random)\n",
    "print('Accuracy для случайного предсказания: {:.3f}'.format(accuracy_baseline))\n",
    "\n",
    "y_pred = np.array(gb_classifier.predict(X_val) > 0.5, dtype=np.int)\n",
    "accuracy_boosting = accuracy_score(y_val, y_pred)\n",
    "print('Accuracy для предсказаний бустинга: {:.3f}'.format(accuracy_boosting))\n",
    "\n",
    "np.testing.assert_array_less(1 - accuracy_boosting, (1 - accuracy_baseline) / 2 + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если все тесты пройдены успешно, попробуйте реализовать дополнительный функционал для вашего класса:\n",
    "- Реализация ранней остановки обучения (1 балл)\n",
    "- Реализация вычисления дополнительной метрики качества на каждой итерации (1 балл)\n",
    "- Реализация бэггинга при обучении отдельных деревьев (1 балл)\n",
    "\n",
    "Для того, чтобы дополнительные баллы были засчитаны, необходимо реализовать функционал и продемонстрировать результат в ячейке внизу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyBoost =  GradientBoosting + R2-score + EarlyStop (with patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " class MyBoost(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 loss=None,\n",
    "                 n_estimators=10, \n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=3,\n",
    "                 max_features='auto',\n",
    "                 random_state=2,\n",
    "                 patience=3,\n",
    "                 decrease_treshold= 0.9995):\n",
    "        self.loss = loss\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.patience = patience\n",
    "        self.decrease_treshold = decrease_treshold\n",
    "        \n",
    "        self.estimators = []\n",
    "        self.loss_values = []\n",
    "        self.loss_values_evalset = []\n",
    "        \n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_evalset=[], y_evalset=[], verbose=True): \n",
    "        iter_prediction = np.array([y_train.mean() for i in range (len(y_train))])\n",
    "        iter_loss = self.loss.forward(y_train, iter_prediction)\n",
    "        self.loss_values.append(iter_loss.sum())\n",
    "        self.estimators.append(iter_prediction)\n",
    "        delta_loss = []\n",
    "        stop_start = max(self.n_estimators * 0.5, self.patience + 1)\n",
    "        if len(y_evalset) != 0:\n",
    "            iter_prediction_eval = np.array([y_evalset.mean() for i in range (len(y_evalset))])\n",
    "        for t in range(1, self.n_estimators):\n",
    "            antigradient = - self.loss.grad(y_train, iter_prediction)\n",
    "            tree = DecisionTreeRegressor (max_depth=self.max_depth, \\\n",
    "                                          max_features=self.max_features, \\\n",
    "                                          random_state=self.random_state). \\\n",
    "                                        fit(X_train, antigradient)\n",
    "            self.estimators.append(tree)\n",
    "            iter_prediction += self.learning_rate * tree.predict(X_train)\n",
    "            iter_loss = self.loss.forward(y_train, iter_prediction)\n",
    "            self.loss_values.append(iter_loss.sum())\n",
    "            if verbose == True and t % 10 == 0:\n",
    "                print ('Iter # %s:' %t, 'Loss value: %s' %self.loss_values[-1],  # добавлена R-2 метрика\n",
    "                       'R2-score: %s' %R2_score(y_train, iter_prediction))\n",
    "            if len(y_evalset) != 0:\n",
    "                iter_prediction_eval += tree.predict(X_evalset)\n",
    "                iter_loss_eval = self.loss.forward(y_evalset, iter_prediction_eval)\n",
    "                self.loss_values_evalset.append(iter_loss_eval.sum())\n",
    "                if t % 10 == 0 and verbose == True:\n",
    "                    print('Loss on evalset: %s' %self.loss_values_evalset[-1], \\\n",
    "                          'R2-score on evalset: %s' %R2_score(y_evalset, iter_prediction_eval))\n",
    "                if t >= stop_start - self.patience: \n",
    "                    delta_loss.append(abs(self.loss_values_evalset[-1] / self.loss_values_evalset[-2]))         #критерий остановки\n",
    "                if t >= stop_start and all([delta >= self.decrease_treshold for delta in delta_loss[-self.patience:]]):\n",
    "                    break \n",
    "    \n",
    "    def predict(self, X):\n",
    "        #prediction = self.estimators[0][:X.shape[0]]\n",
    "        prediction = np.zeros(X.shape[0])\n",
    "        for tree in self.estimators[1:]:\n",
    "            prediction += self.learning_rate * tree.predict(X)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R2_score (y, y_pred):\n",
    "    return 1 - ((y - y_pred) ** 2) .sum() / ((y - y.mean()) ** 2) .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_score (np.array([1,2]), np.array([2,3] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Решение задачи предсказания цены футболиста в FIFA 18 Ultimate Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно обучить какой-либо из рассмотренных в курсе ансамблей предсказывать трансферную стоимость футболиста из FIFA 18 Ultimate Team. Решение будет оцениваться по метрике MSE на тестовой выборке. Засчитывается только решение, качество которого на тестовой выборке окажется выше, чем у бейзлайна (см. в конце ноутбука).\n",
    "\n",
    "Данные для обучения - `train_with_targets.csv`, столбец с целевой переменной - `price_ps4`.\n",
    "Для отправки решения заполните столбец `price_ps4` в файле `test_submission.csv` предсказаниями своей модели на признаках из файла `test.csv` (убедитесь, что порядок следования `player_id` верный)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения моделей следует использовать:\n",
    "* \\*Свой класс для градиентного бустинга, реализованный выше\n",
    "* Любые ансамбли из `sklearn` (`RandomForestRegressor`, `GradientBoostingRegressor`, ...)\n",
    "* Любые фреймворки для градиентного бустинга (`XGBoost`, `LightGBM`, `CatBoost`, ...)\n",
    "* \\*Стекинг/блендинг (свой или тот, что был реализован на лекциях)\n",
    "* Подбор гиперпараметров с помощью `RandomizedSearch` / `hyperopt` / ... \n",
    "\n",
    "Использование пунктов со звездочкой может накинуть дополнительных баллов за задание (по 1 баллу за пункт, т.е. максимум 2 дополнительных балла).\n",
    "\n",
    "Удачи!\n",
    "\n",
    "*Ниже приведен пример бейзлайна на случайном лесе из `sklearn`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline на RandomForestClassifier из Sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_ID</th>\n",
       "      <th>player_name</th>\n",
       "      <th>player_extended_name</th>\n",
       "      <th>quality</th>\n",
       "      <th>revision</th>\n",
       "      <th>origin</th>\n",
       "      <th>overall</th>\n",
       "      <th>club</th>\n",
       "      <th>league</th>\n",
       "      <th>nationality</th>\n",
       "      <th>...</th>\n",
       "      <th>cam</th>\n",
       "      <th>cf</th>\n",
       "      <th>rf</th>\n",
       "      <th>lf</th>\n",
       "      <th>rw</th>\n",
       "      <th>lw</th>\n",
       "      <th>st</th>\n",
       "      <th>price_ps4</th>\n",
       "      <th>traits</th>\n",
       "      <th>specialties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20920</td>\n",
       "      <td>Sacko</td>\n",
       "      <td>Hadi Sacko</td>\n",
       "      <td>Silver - Rare</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>68</td>\n",
       "      <td>UD Las Palmas</td>\n",
       "      <td>LaLiga Santander</td>\n",
       "      <td>France</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Tries To Beat Defensive Line, Selfish, Dribble...</td>\n",
       "      <td>Speedster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2996</td>\n",
       "      <td>Koo Ja Ryong</td>\n",
       "      <td>Ja Ryong Koo</td>\n",
       "      <td>Silver - Rare</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>Suwon Samsung Bluewings</td>\n",
       "      <td>K LEAGUE Classic</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Leadership</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12998</td>\n",
       "      <td>Gipson</td>\n",
       "      <td>Ken Gipson</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>SV Sandhausen</td>\n",
       "      <td>Bundesliga 2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16112</td>\n",
       "      <td>Yoda</td>\n",
       "      <td>Abdoul Karim Yoda</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>69</td>\n",
       "      <td>CF Reus</td>\n",
       "      <td>LaLiga 1 I 2 I 3</td>\n",
       "      <td>France</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Flair, Technical Dribbler</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16502</td>\n",
       "      <td>Ronan</td>\n",
       "      <td>Connor Ronan</td>\n",
       "      <td>Bronze - Rare</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>64</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>EFL League One</td>\n",
       "      <td>Republic of Ireland</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_ID   player_name player_extended_name        quality revision  \\\n",
       "0      20920         Sacko           Hadi Sacko  Silver - Rare   Normal   \n",
       "1       2996  Koo Ja Ryong         Ja Ryong Koo  Silver - Rare   Normal   \n",
       "2      12998        Gipson           Ken Gipson         Bronze   Normal   \n",
       "3      16112          Yoda    Abdoul Karim Yoda         Silver   Normal   \n",
       "4      16502         Ronan         Connor Ronan  Bronze - Rare   Normal   \n",
       "\n",
       "      origin  overall                     club            league  \\\n",
       "0  Transfers       68            UD Las Palmas  LaLiga Santander   \n",
       "1        NaN       73  Suwon Samsung Bluewings  K LEAGUE Classic   \n",
       "2        NaN       60            SV Sandhausen      Bundesliga 2   \n",
       "3  Transfers       69                  CF Reus  LaLiga 1 I 2 I 3   \n",
       "4  Transfers       64               Portsmouth    EFL League One   \n",
       "\n",
       "           nationality     ...        cam    cf    rf    lf    rw    lw    st  \\\n",
       "0               France     ...       65.0  67.0  67.0  67.0  68.0  68.0  66.0   \n",
       "1       Korea Republic     ...       48.0  46.0  46.0  46.0  46.0  46.0  46.0   \n",
       "2              Germany     ...       49.0  49.0  49.0  49.0  51.0  51.0  49.0   \n",
       "3               France     ...       66.0  67.0  67.0  67.0  69.0  69.0  65.0   \n",
       "4  Republic of Ireland     ...       63.0  61.0  61.0  61.0  63.0  63.0  56.0   \n",
       "\n",
       "   price_ps4                                             traits  specialties  \n",
       "0     1000.0  Tries To Beat Defensive Line, Selfish, Dribble...    Speedster  \n",
       "1      450.0                                         Leadership          NaN  \n",
       "2      200.0                                                NaN          NaN  \n",
       "3      350.0                          Flair, Technical Dribbler          NaN  \n",
       "4      200.0                                                NaN          NaN  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.read_csv('./data/train_with_targets.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrkagan/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3660: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_ID</th>\n",
       "      <th>overall</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>intl_rep</th>\n",
       "      <th>pace</th>\n",
       "      <th>pace_acceleration</th>\n",
       "      <th>pace_sprint_speed</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>...</th>\n",
       "      <th>rm</th>\n",
       "      <th>lm</th>\n",
       "      <th>cam</th>\n",
       "      <th>cf</th>\n",
       "      <th>rf</th>\n",
       "      <th>lf</th>\n",
       "      <th>rw</th>\n",
       "      <th>lw</th>\n",
       "      <th>st</th>\n",
       "      <th>price_ps4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20920</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>183</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2996</td>\n",
       "      <td>73</td>\n",
       "      <td>26</td>\n",
       "      <td>183</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12998</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>178</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16112</td>\n",
       "      <td>69</td>\n",
       "      <td>29</td>\n",
       "      <td>182</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16502</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_ID  overall  age  height  weight  intl_rep  pace  pace_acceleration  \\\n",
       "0      20920       68   24     183      79         1  91.0               90.0   \n",
       "1       2996       73   26     183      75         1  72.0               69.0   \n",
       "2      12998       60   22     178      69         1  76.0               75.0   \n",
       "3      16112       69   29     182      73         1  84.0               79.0   \n",
       "4      16502       64   20     170      63         1  81.0               80.0   \n",
       "\n",
       "   pace_sprint_speed  dribbling    ...        rm    lm   cam    cf    rf  \\\n",
       "0               91.0       69.0    ...      67.0  67.0  65.0  67.0  67.0   \n",
       "1               74.0       49.0    ...      48.0  48.0  48.0  46.0  46.0   \n",
       "2               76.0       55.0    ...      52.0  52.0  49.0  49.0  49.0   \n",
       "3               88.0       73.0    ...      68.0  68.0  66.0  67.0  67.0   \n",
       "4               82.0       68.0    ...      63.0  63.0  63.0  61.0  61.0   \n",
       "\n",
       "     lf    rw    lw    st  price_ps4  \n",
       "0  67.0  68.0  68.0  66.0     1000.0  \n",
       "1  46.0  46.0  46.0  46.0      450.0  \n",
       "2  49.0  51.0  51.0  49.0      200.0  \n",
       "3  67.0  69.0  69.0  65.0      350.0  \n",
       "4  61.0  63.0  63.0  56.0      200.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_num = data_train.select_dtypes(include=['int', 'float'])\n",
    "data_train_num.fillna(data_train_num.mean(), inplace=True)\n",
    "data_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18629, 64) (18629,)\n",
      "(14903, 64) (14903,)\n",
      "(3726, 64) (3726,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X = data_train_num.drop(labels=['price_ps4'], axis=1).values[:, 1:]\n",
    "y = data_train_num['price_ps4'].values\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = tts(X, y, test_size=0.2, random_state=179)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=2, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=10, verbose=1, n_jobs=-1, random_state=2)\n",
    "rf_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 442677211.07112485\n",
      "val MSE: 1075785619.1330426\n"
     ]
    }
   ],
   "source": [
    "rf_regressor_pred = rf_regressor.predict(X_train)\n",
    "print('train MSE:', mean_squared_error(rf_regressor_pred, y_train))\n",
    "rf_regressor_pred = rf_regressor.predict(X_val)\n",
    "print('val MSE:', mean_squared_error(rf_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=400,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_regressor = XGBRegressor(n_estimators=400, max_depth = 3)\n",
    "xgb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 56354668.77023895\n",
      "val MSE: 678222891.6151305\n"
     ]
    }
   ],
   "source": [
    "xgb_regressor_pred = xgb_regressor.predict(X_train)\n",
    "print('train MSE:', mean_squared_error(xgb_regressor_pred, y_train))\n",
    "xgb_regressor_pred = xgb_regressor.predict(X_val)\n",
    "print('val MSE:', mean_squared_error(xgb_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6304442814189122\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(xgb_regressor_pred, y_val) / mean_squared_error(rf_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boost = MyBoost(loss = MSELoss(), n_estimators = 400, learning_rate = 0.08, max_depth = 2, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter # 10: Loss value: 2508348317.8777065 R2-score: 0.5673170673252816\n",
      "Loss on evalset: 123677861812.57959 R2-score on evalset: -17.49341184983749\n",
      "Iter # 20: Loss value: 1423724409.4447322 R2-score: 0.7544115988961457\n",
      "Loss on evalset: 297451465559.1633 R2-score on evalset: -43.47758375916432\n",
      "Iter # 30: Loss value: 978210069.0421102 R2-score: 0.8312615523017984\n",
      "Loss on evalset: 445730459224.3233 R2-score on evalset: -65.64957524042656\n",
      "Iter # 40: Loss value: 767666736.8330663 R2-score: 0.8675796767767894\n",
      "Loss on evalset: 556881374666.6681 R2-score on evalset: -82.26984686087812\n",
      "Iter # 50: Loss value: 639204828.725987 R2-score: 0.8897389896364125\n",
      "Loss on evalset: 623038274047.124 R2-score on evalset: -92.1622137648683\n",
      "Iter # 60: Loss value: 540815617.3587542 R2-score: 0.9067108480559586\n",
      "Loss on evalset: 674196662927.7417 R2-score on evalset: -99.81187022947557\n",
      "Iter # 70: Loss value: 480987437.491092 R2-score: 0.9170310384925217\n",
      "Loss on evalset: 702446629948.6797 R2-score on evalset: -104.0360560878488\n",
      "Iter # 80: Loss value: 434542592.4256358 R2-score: 0.9250426418361704\n",
      "Loss on evalset: 711936121694.0701 R2-score on evalset: -105.45500913669012\n",
      "Iter # 90: Loss value: 401406751.4372078 R2-score: 0.9307584799250553\n",
      "Loss on evalset: 722241323274.8914 R2-score on evalset: -106.99593436159842\n",
      "Iter # 100: Loss value: 376587475.17973727 R2-score: 0.9350397343112216\n",
      "Loss on evalset: 733567531215.386 R2-score on evalset: -108.68952952140057\n",
      "Iter # 110: Loss value: 351548710.202608 R2-score: 0.9393588498756913\n",
      "Loss on evalset: 738408352057.1226 R2-score on evalset: -109.41337202809895\n",
      "Iter # 120: Loss value: 337271492.3414861 R2-score: 0.9418216292475023\n",
      "Loss on evalset: 743522392766.1244 R2-score on evalset: -110.17806879486325\n",
      "Iter # 130: Loss value: 323901681.5500789 R2-score: 0.9441278834871156\n",
      "Loss on evalset: 747564361023.1694 R2-score on evalset: -110.78245977127567\n",
      "Iter # 140: Loss value: 304980559.16393685 R2-score: 0.947391723148132\n",
      "Loss on evalset: 754683936341.9778 R2-score on evalset: -111.84704187705452\n",
      "Iter # 150: Loss value: 296080599.0738728 R2-score: 0.948926940886837\n",
      "Loss on evalset: 759365946083.0979 R2-score on evalset: -112.54713753814138\n",
      "Iter # 160: Loss value: 279016003.5186426 R2-score: 0.9518705349631145\n",
      "Loss on evalset: 757501753863.8989 R2-score on evalset: -112.2683869681392\n",
      "Iter # 170: Loss value: 266052901.46828356 R2-score: 0.9541066331045626\n",
      "Loss on evalset: 756720241576.6923 R2-score on evalset: -112.1515283130718\n",
      "Iter # 180: Loss value: 255270246.8361037 R2-score: 0.9559666102835764\n",
      "Loss on evalset: 755814248975.0767 R2-score on evalset: -112.01605625631875\n",
      "Iter # 190: Loss value: 244432732.65681696 R2-score: 0.9578360505780428\n",
      "Loss on evalset: 756093080904.3435 R2-score on evalset: -112.05774968171629\n",
      "Iter # 200: Loss value: 235178177.84411287 R2-score: 0.9594324348953325\n",
      "Loss on evalset: 753331418166.6099 R2-score on evalset: -111.64480135247808\n",
      "Iter # 210: Loss value: 226706299.91916433 R2-score: 0.9608938096811638\n",
      "Loss on evalset: 762037602354.9816 R2-score on evalset: -112.94662730157224\n",
      "Iter # 220: Loss value: 219076759.22183385 R2-score: 0.9622098836970226\n",
      "Loss on evalset: 763479559809.3025 R2-score on evalset: -113.16224158113597\n"
     ]
    }
   ],
   "source": [
    "boost.fit(X_train, y_train, X_evalset = X_val, y_evalset = y_val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 592367214.2146995\n",
      "val MSE: 1154662873.4741354\n"
     ]
    }
   ],
   "source": [
    "myboost_pred = boost.predict(X_train)\n",
    "print('train MSE:', mean_squared_error(myboost_pred, y_train))\n",
    "myboost_pred = boost.predict(X_val)\n",
    "print('val MSE:', mean_squared_error(myboost_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0733206067623944\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(myboost_pred, y_val) / mean_squared_error(rf_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catboost = CatBoostRegressor(iterations = 400, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 106861.8391752\ttotal: 74.9ms\tremaining: 29.9s\n",
      "1:\tlearn: 105798.3704074\ttotal: 94.1ms\tremaining: 18.7s\n",
      "2:\tlearn: 104335.5514595\ttotal: 104ms\tremaining: 13.8s\n",
      "3:\tlearn: 103000.3428721\ttotal: 113ms\tremaining: 11.2s\n",
      "4:\tlearn: 101506.0822534\ttotal: 124ms\tremaining: 9.8s\n",
      "5:\tlearn: 100020.3043489\ttotal: 136ms\tremaining: 8.94s\n",
      "6:\tlearn: 98661.9438273\ttotal: 145ms\tremaining: 8.13s\n",
      "7:\tlearn: 97272.4114258\ttotal: 153ms\tremaining: 7.5s\n",
      "8:\tlearn: 95967.3003799\ttotal: 162ms\tremaining: 7.02s\n",
      "9:\tlearn: 94736.1434176\ttotal: 171ms\tremaining: 6.69s\n",
      "10:\tlearn: 93540.2945732\ttotal: 184ms\tremaining: 6.5s\n",
      "11:\tlearn: 92331.5302411\ttotal: 191ms\tremaining: 6.17s\n",
      "12:\tlearn: 91232.2767075\ttotal: 202ms\tremaining: 6.01s\n",
      "13:\tlearn: 90057.7880362\ttotal: 212ms\tremaining: 5.83s\n",
      "14:\tlearn: 89068.3553024\ttotal: 220ms\tremaining: 5.63s\n",
      "15:\tlearn: 87976.3631326\ttotal: 230ms\tremaining: 5.53s\n",
      "16:\tlearn: 87024.2613631\ttotal: 238ms\tremaining: 5.36s\n",
      "17:\tlearn: 85993.8532618\ttotal: 250ms\tremaining: 5.29s\n",
      "18:\tlearn: 84847.7678148\ttotal: 257ms\tremaining: 5.15s\n",
      "19:\tlearn: 83893.1403057\ttotal: 267ms\tremaining: 5.08s\n",
      "20:\tlearn: 82865.8045545\ttotal: 278ms\tremaining: 5.01s\n",
      "21:\tlearn: 82043.8331032\ttotal: 286ms\tremaining: 4.92s\n",
      "22:\tlearn: 81405.6844826\ttotal: 300ms\tremaining: 4.92s\n",
      "23:\tlearn: 80684.6508770\ttotal: 311ms\tremaining: 4.86s\n",
      "24:\tlearn: 79809.1996782\ttotal: 319ms\tremaining: 4.79s\n",
      "25:\tlearn: 78868.3935180\ttotal: 331ms\tremaining: 4.77s\n",
      "26:\tlearn: 78009.2476925\ttotal: 340ms\tremaining: 4.69s\n",
      "27:\tlearn: 77063.2197028\ttotal: 349ms\tremaining: 4.64s\n",
      "28:\tlearn: 76031.5790260\ttotal: 359ms\tremaining: 4.59s\n",
      "29:\tlearn: 75181.6217354\ttotal: 367ms\tremaining: 4.53s\n",
      "30:\tlearn: 74449.8568405\ttotal: 379ms\tremaining: 4.51s\n",
      "31:\tlearn: 73688.2405539\ttotal: 386ms\tremaining: 4.43s\n",
      "32:\tlearn: 72966.0908978\ttotal: 393ms\tremaining: 4.37s\n",
      "33:\tlearn: 72245.3829709\ttotal: 400ms\tremaining: 4.3s\n",
      "34:\tlearn: 71512.6717651\ttotal: 407ms\tremaining: 4.25s\n",
      "35:\tlearn: 70870.7368116\ttotal: 414ms\tremaining: 4.18s\n",
      "36:\tlearn: 70718.3975665\ttotal: 421ms\tremaining: 4.13s\n",
      "37:\tlearn: 69995.4692675\ttotal: 428ms\tremaining: 4.08s\n",
      "38:\tlearn: 69384.7536891\ttotal: 436ms\tremaining: 4.04s\n",
      "39:\tlearn: 68577.5655209\ttotal: 443ms\tremaining: 3.98s\n",
      "40:\tlearn: 67902.1987461\ttotal: 449ms\tremaining: 3.93s\n",
      "41:\tlearn: 67327.8744100\ttotal: 456ms\tremaining: 3.89s\n",
      "42:\tlearn: 66662.1551540\ttotal: 463ms\tremaining: 3.84s\n",
      "43:\tlearn: 66044.0143414\ttotal: 470ms\tremaining: 3.8s\n",
      "44:\tlearn: 65517.2097332\ttotal: 479ms\tremaining: 3.78s\n",
      "45:\tlearn: 65068.0425176\ttotal: 485ms\tremaining: 3.73s\n",
      "46:\tlearn: 64909.2070156\ttotal: 492ms\tremaining: 3.69s\n",
      "47:\tlearn: 64351.4278723\ttotal: 499ms\tremaining: 3.65s\n",
      "48:\tlearn: 63840.3936388\ttotal: 505ms\tremaining: 3.62s\n",
      "49:\tlearn: 63421.6667940\ttotal: 511ms\tremaining: 3.58s\n",
      "50:\tlearn: 62667.1062968\ttotal: 518ms\tremaining: 3.54s\n",
      "51:\tlearn: 62147.7393081\ttotal: 524ms\tremaining: 3.51s\n",
      "52:\tlearn: 61711.5668195\ttotal: 535ms\tremaining: 3.5s\n",
      "53:\tlearn: 61184.1561327\ttotal: 547ms\tremaining: 3.5s\n",
      "54:\tlearn: 60740.1254633\ttotal: 559ms\tremaining: 3.51s\n",
      "55:\tlearn: 60249.8322603\ttotal: 572ms\tremaining: 3.52s\n",
      "56:\tlearn: 60128.7271947\ttotal: 584ms\tremaining: 3.52s\n",
      "57:\tlearn: 59748.2089088\ttotal: 597ms\tremaining: 3.52s\n",
      "58:\tlearn: 59116.5612150\ttotal: 611ms\tremaining: 3.53s\n",
      "59:\tlearn: 58741.1510778\ttotal: 619ms\tremaining: 3.51s\n",
      "60:\tlearn: 58270.7954830\ttotal: 626ms\tremaining: 3.48s\n",
      "61:\tlearn: 58156.2070926\ttotal: 632ms\tremaining: 3.45s\n",
      "62:\tlearn: 57682.3451156\ttotal: 639ms\tremaining: 3.42s\n",
      "63:\tlearn: 57361.5571077\ttotal: 646ms\tremaining: 3.39s\n",
      "64:\tlearn: 56952.1742835\ttotal: 652ms\tremaining: 3.36s\n",
      "65:\tlearn: 56502.0243615\ttotal: 658ms\tremaining: 3.33s\n",
      "66:\tlearn: 56078.8907678\ttotal: 665ms\tremaining: 3.3s\n",
      "67:\tlearn: 55678.5829362\ttotal: 672ms\tremaining: 3.28s\n",
      "68:\tlearn: 55448.6170873\ttotal: 680ms\tremaining: 3.26s\n",
      "69:\tlearn: 54975.8574551\ttotal: 687ms\tremaining: 3.24s\n",
      "70:\tlearn: 54653.8588843\ttotal: 694ms\tremaining: 3.21s\n",
      "71:\tlearn: 54302.2156304\ttotal: 700ms\tremaining: 3.19s\n",
      "72:\tlearn: 53953.3080855\ttotal: 707ms\tremaining: 3.17s\n",
      "73:\tlearn: 53417.7372834\ttotal: 715ms\tremaining: 3.15s\n",
      "74:\tlearn: 52928.0875877\ttotal: 726ms\tremaining: 3.15s\n",
      "75:\tlearn: 52519.9705208\ttotal: 734ms\tremaining: 3.13s\n",
      "76:\tlearn: 52288.4013997\ttotal: 741ms\tremaining: 3.11s\n",
      "77:\tlearn: 52218.3277310\ttotal: 749ms\tremaining: 3.09s\n",
      "78:\tlearn: 51783.1112917\ttotal: 755ms\tremaining: 3.07s\n",
      "79:\tlearn: 51589.7079680\ttotal: 762ms\tremaining: 3.05s\n",
      "80:\tlearn: 51344.8640450\ttotal: 769ms\tremaining: 3.03s\n",
      "81:\tlearn: 51155.3251795\ttotal: 775ms\tremaining: 3s\n",
      "82:\tlearn: 50817.3365437\ttotal: 781ms\tremaining: 2.98s\n",
      "83:\tlearn: 50392.6116702\ttotal: 788ms\tremaining: 2.96s\n",
      "84:\tlearn: 50299.2297814\ttotal: 794ms\tremaining: 2.94s\n",
      "85:\tlearn: 50143.6484344\ttotal: 801ms\tremaining: 2.92s\n",
      "86:\tlearn: 50006.1541918\ttotal: 807ms\tremaining: 2.9s\n",
      "87:\tlearn: 49911.5588584\ttotal: 813ms\tremaining: 2.88s\n",
      "88:\tlearn: 49645.8305566\ttotal: 820ms\tremaining: 2.87s\n",
      "89:\tlearn: 49435.8384143\ttotal: 826ms\tremaining: 2.85s\n",
      "90:\tlearn: 49150.2122060\ttotal: 834ms\tremaining: 2.83s\n",
      "91:\tlearn: 48921.0583267\ttotal: 840ms\tremaining: 2.81s\n",
      "92:\tlearn: 48556.7819678\ttotal: 847ms\tremaining: 2.79s\n",
      "93:\tlearn: 48341.9945153\ttotal: 854ms\tremaining: 2.78s\n",
      "94:\tlearn: 48103.7807862\ttotal: 860ms\tremaining: 2.76s\n",
      "95:\tlearn: 47844.0922934\ttotal: 867ms\tremaining: 2.75s\n",
      "96:\tlearn: 47543.6789793\ttotal: 873ms\tremaining: 2.73s\n",
      "97:\tlearn: 47461.1807281\ttotal: 882ms\tremaining: 2.72s\n",
      "98:\tlearn: 47380.5331454\ttotal: 888ms\tremaining: 2.7s\n",
      "99:\tlearn: 47263.2319228\ttotal: 895ms\tremaining: 2.68s\n",
      "100:\tlearn: 46916.0702204\ttotal: 902ms\tremaining: 2.67s\n",
      "101:\tlearn: 46793.3174522\ttotal: 910ms\tremaining: 2.66s\n",
      "102:\tlearn: 46588.3249118\ttotal: 917ms\tremaining: 2.65s\n",
      "103:\tlearn: 46401.5451017\ttotal: 924ms\tremaining: 2.63s\n",
      "104:\tlearn: 46194.0370465\ttotal: 931ms\tremaining: 2.61s\n",
      "105:\tlearn: 46049.8055717\ttotal: 938ms\tremaining: 2.6s\n",
      "106:\tlearn: 45794.6764936\ttotal: 945ms\tremaining: 2.59s\n",
      "107:\tlearn: 45632.9882240\ttotal: 952ms\tremaining: 2.57s\n",
      "108:\tlearn: 45386.5588834\ttotal: 959ms\tremaining: 2.56s\n",
      "109:\tlearn: 45208.2879147\ttotal: 966ms\tremaining: 2.55s\n",
      "110:\tlearn: 44973.6561066\ttotal: 973ms\tremaining: 2.53s\n",
      "111:\tlearn: 44900.1022699\ttotal: 980ms\tremaining: 2.52s\n",
      "112:\tlearn: 44708.4967368\ttotal: 987ms\tremaining: 2.5s\n",
      "113:\tlearn: 44573.6789627\ttotal: 1000ms\tremaining: 2.51s\n",
      "114:\tlearn: 44493.3265779\ttotal: 1.01s\tremaining: 2.51s\n",
      "115:\tlearn: 44359.3503456\ttotal: 1.03s\tremaining: 2.52s\n",
      "116:\tlearn: 44190.2928508\ttotal: 1.05s\tremaining: 2.55s\n",
      "117:\tlearn: 43983.3013433\ttotal: 1.07s\tremaining: 2.55s\n",
      "118:\tlearn: 43894.7790432\ttotal: 1.08s\tremaining: 2.55s\n",
      "119:\tlearn: 43833.7229977\ttotal: 1.09s\tremaining: 2.56s\n",
      "120:\tlearn: 43638.9212840\ttotal: 1.11s\tremaining: 2.57s\n",
      "121:\tlearn: 43394.2215008\ttotal: 1.13s\tremaining: 2.58s\n",
      "122:\tlearn: 43327.2169151\ttotal: 1.16s\tremaining: 2.6s\n",
      "123:\tlearn: 43094.9493191\ttotal: 1.17s\tremaining: 2.6s\n",
      "124:\tlearn: 42964.3166831\ttotal: 1.18s\tremaining: 2.6s\n",
      "125:\tlearn: 42863.1669558\ttotal: 1.2s\tremaining: 2.61s\n",
      "126:\tlearn: 42677.5633527\ttotal: 1.21s\tremaining: 2.61s\n",
      "127:\tlearn: 42557.6823383\ttotal: 1.23s\tremaining: 2.61s\n",
      "128:\tlearn: 42375.8837044\ttotal: 1.25s\tremaining: 2.62s\n",
      "129:\tlearn: 42191.9658120\ttotal: 1.26s\tremaining: 2.62s\n",
      "130:\tlearn: 42015.5527796\ttotal: 1.27s\tremaining: 2.62s\n",
      "131:\tlearn: 41853.4483648\ttotal: 1.29s\tremaining: 2.62s\n",
      "132:\tlearn: 41774.5429221\ttotal: 1.31s\tremaining: 2.63s\n",
      "133:\tlearn: 41694.2526430\ttotal: 1.33s\tremaining: 2.63s\n",
      "134:\tlearn: 41633.6022874\ttotal: 1.34s\tremaining: 2.64s\n",
      "135:\tlearn: 41467.5810595\ttotal: 1.36s\tremaining: 2.63s\n",
      "136:\tlearn: 41264.5203374\ttotal: 1.37s\tremaining: 2.63s\n",
      "137:\tlearn: 41151.3774020\ttotal: 1.39s\tremaining: 2.63s\n",
      "138:\tlearn: 41030.6928906\ttotal: 1.4s\tremaining: 2.63s\n",
      "139:\tlearn: 40929.5914193\ttotal: 1.41s\tremaining: 2.62s\n",
      "140:\tlearn: 40800.4169524\ttotal: 1.43s\tremaining: 2.62s\n",
      "141:\tlearn: 40735.6247826\ttotal: 1.45s\tremaining: 2.63s\n",
      "142:\tlearn: 40649.1563252\ttotal: 1.46s\tremaining: 2.62s\n",
      "143:\tlearn: 40543.9999865\ttotal: 1.48s\tremaining: 2.62s\n",
      "144:\tlearn: 40454.1618182\ttotal: 1.49s\tremaining: 2.63s\n",
      "145:\tlearn: 40422.1933357\ttotal: 1.51s\tremaining: 2.63s\n",
      "146:\tlearn: 40361.3125934\ttotal: 1.52s\tremaining: 2.63s\n",
      "147:\tlearn: 40299.9656540\ttotal: 1.54s\tremaining: 2.62s\n",
      "148:\tlearn: 40235.1737615\ttotal: 1.55s\tremaining: 2.62s\n",
      "149:\tlearn: 40187.2297547\ttotal: 1.57s\tremaining: 2.61s\n",
      "150:\tlearn: 40158.4605315\ttotal: 1.58s\tremaining: 2.62s\n",
      "151:\tlearn: 40032.6665230\ttotal: 1.6s\tremaining: 2.62s\n",
      "152:\tlearn: 39976.7552696\ttotal: 1.62s\tremaining: 2.62s\n",
      "153:\tlearn: 39859.8974507\ttotal: 1.64s\tremaining: 2.62s\n",
      "154:\tlearn: 39725.2128801\ttotal: 1.65s\tremaining: 2.61s\n",
      "155:\tlearn: 39627.4411189\ttotal: 1.68s\tremaining: 2.62s\n",
      "156:\tlearn: 39601.6498994\ttotal: 1.7s\tremaining: 2.64s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157:\tlearn: 39552.8830277\ttotal: 1.72s\tremaining: 2.64s\n",
      "158:\tlearn: 39536.6158411\ttotal: 1.74s\tremaining: 2.64s\n",
      "159:\tlearn: 39485.6076751\ttotal: 1.76s\tremaining: 2.64s\n",
      "160:\tlearn: 39381.9289198\ttotal: 1.78s\tremaining: 2.64s\n",
      "161:\tlearn: 39345.8457868\ttotal: 1.79s\tremaining: 2.63s\n",
      "162:\tlearn: 39193.4427615\ttotal: 1.81s\tremaining: 2.63s\n",
      "163:\tlearn: 39116.7646885\ttotal: 1.82s\tremaining: 2.62s\n",
      "164:\tlearn: 39047.6542380\ttotal: 1.83s\tremaining: 2.6s\n",
      "165:\tlearn: 38975.8987911\ttotal: 1.84s\tremaining: 2.59s\n",
      "166:\tlearn: 38845.0921987\ttotal: 1.86s\tremaining: 2.59s\n",
      "167:\tlearn: 38703.9449435\ttotal: 1.87s\tremaining: 2.59s\n",
      "168:\tlearn: 38694.1446956\ttotal: 1.89s\tremaining: 2.58s\n",
      "169:\tlearn: 38595.1103101\ttotal: 1.91s\tremaining: 2.58s\n",
      "170:\tlearn: 38549.5007286\ttotal: 1.92s\tremaining: 2.57s\n",
      "171:\tlearn: 38513.3951060\ttotal: 1.94s\tremaining: 2.57s\n",
      "172:\tlearn: 38401.8130608\ttotal: 1.96s\tremaining: 2.57s\n",
      "173:\tlearn: 38321.9577738\ttotal: 1.97s\tremaining: 2.56s\n",
      "174:\tlearn: 38278.6208298\ttotal: 2s\tremaining: 2.57s\n",
      "175:\tlearn: 38165.1994920\ttotal: 2.04s\tremaining: 2.6s\n",
      "176:\tlearn: 38145.6932782\ttotal: 2.06s\tremaining: 2.6s\n",
      "177:\tlearn: 38108.9180059\ttotal: 2.08s\tremaining: 2.6s\n",
      "178:\tlearn: 38090.0140032\ttotal: 2.11s\tremaining: 2.6s\n",
      "179:\tlearn: 38046.4413881\ttotal: 2.13s\tremaining: 2.6s\n",
      "180:\tlearn: 37955.3636000\ttotal: 2.15s\tremaining: 2.6s\n",
      "181:\tlearn: 37894.8207095\ttotal: 2.17s\tremaining: 2.6s\n",
      "182:\tlearn: 37850.2426242\ttotal: 2.19s\tremaining: 2.6s\n",
      "183:\tlearn: 37809.8208528\ttotal: 2.21s\tremaining: 2.6s\n",
      "184:\tlearn: 37729.7484033\ttotal: 2.22s\tremaining: 2.58s\n",
      "185:\tlearn: 37685.8786653\ttotal: 2.24s\tremaining: 2.57s\n",
      "186:\tlearn: 37638.6796362\ttotal: 2.25s\tremaining: 2.56s\n",
      "187:\tlearn: 37629.2982999\ttotal: 2.26s\tremaining: 2.55s\n",
      "188:\tlearn: 37582.1951134\ttotal: 2.28s\tremaining: 2.54s\n",
      "189:\tlearn: 37526.4429836\ttotal: 2.29s\tremaining: 2.53s\n",
      "190:\tlearn: 37466.7193724\ttotal: 2.3s\tremaining: 2.52s\n",
      "191:\tlearn: 37431.3046047\ttotal: 2.31s\tremaining: 2.5s\n",
      "192:\tlearn: 37349.4780221\ttotal: 2.32s\tremaining: 2.49s\n",
      "193:\tlearn: 37315.3169868\ttotal: 2.33s\tremaining: 2.47s\n",
      "194:\tlearn: 37251.1649385\ttotal: 2.33s\tremaining: 2.45s\n",
      "195:\tlearn: 37185.6559537\ttotal: 2.34s\tremaining: 2.43s\n",
      "196:\tlearn: 37166.4490125\ttotal: 2.35s\tremaining: 2.42s\n",
      "197:\tlearn: 37082.2726929\ttotal: 2.35s\tremaining: 2.4s\n",
      "198:\tlearn: 37033.2796883\ttotal: 2.36s\tremaining: 2.38s\n",
      "199:\tlearn: 36944.6916199\ttotal: 2.37s\tremaining: 2.37s\n",
      "200:\tlearn: 36910.4148278\ttotal: 2.38s\tremaining: 2.35s\n",
      "201:\tlearn: 36812.1892619\ttotal: 2.38s\tremaining: 2.33s\n",
      "202:\tlearn: 36741.6331615\ttotal: 2.39s\tremaining: 2.32s\n",
      "203:\tlearn: 36715.0631553\ttotal: 2.4s\tremaining: 2.3s\n",
      "204:\tlearn: 36701.9944682\ttotal: 2.4s\tremaining: 2.29s\n",
      "205:\tlearn: 36659.7359382\ttotal: 2.41s\tremaining: 2.27s\n",
      "206:\tlearn: 36647.2029549\ttotal: 2.42s\tremaining: 2.25s\n",
      "207:\tlearn: 36617.6791289\ttotal: 2.42s\tremaining: 2.24s\n",
      "208:\tlearn: 36577.3277998\ttotal: 2.43s\tremaining: 2.22s\n",
      "209:\tlearn: 36489.3223704\ttotal: 2.44s\tremaining: 2.2s\n",
      "210:\tlearn: 36435.0027790\ttotal: 2.44s\tremaining: 2.19s\n",
      "211:\tlearn: 36406.7296174\ttotal: 2.45s\tremaining: 2.17s\n",
      "212:\tlearn: 36394.3231690\ttotal: 2.46s\tremaining: 2.16s\n",
      "213:\tlearn: 36276.3530024\ttotal: 2.46s\tremaining: 2.14s\n",
      "214:\tlearn: 36225.3170663\ttotal: 2.47s\tremaining: 2.13s\n",
      "215:\tlearn: 36194.6991543\ttotal: 2.48s\tremaining: 2.11s\n",
      "216:\tlearn: 36158.9397637\ttotal: 2.48s\tremaining: 2.09s\n",
      "217:\tlearn: 36095.1459484\ttotal: 2.49s\tremaining: 2.08s\n",
      "218:\tlearn: 35994.5691722\ttotal: 2.5s\tremaining: 2.06s\n",
      "219:\tlearn: 35990.6152194\ttotal: 2.5s\tremaining: 2.05s\n",
      "220:\tlearn: 35908.8304087\ttotal: 2.51s\tremaining: 2.03s\n",
      "221:\tlearn: 35826.1157733\ttotal: 2.52s\tremaining: 2.02s\n",
      "222:\tlearn: 35826.0698135\ttotal: 2.52s\tremaining: 2s\n",
      "223:\tlearn: 35798.3294185\ttotal: 2.53s\tremaining: 1.99s\n",
      "224:\tlearn: 35771.6650000\ttotal: 2.54s\tremaining: 1.97s\n",
      "225:\tlearn: 35681.0956413\ttotal: 2.54s\tremaining: 1.96s\n",
      "226:\tlearn: 35608.1277992\ttotal: 2.55s\tremaining: 1.94s\n",
      "227:\tlearn: 35581.5781229\ttotal: 2.56s\tremaining: 1.93s\n",
      "228:\tlearn: 35550.3758285\ttotal: 2.58s\tremaining: 1.92s\n",
      "229:\tlearn: 35457.3179105\ttotal: 2.58s\tremaining: 1.91s\n",
      "230:\tlearn: 35379.6245852\ttotal: 2.59s\tremaining: 1.9s\n",
      "231:\tlearn: 35322.9572358\ttotal: 2.6s\tremaining: 1.89s\n",
      "232:\tlearn: 35319.7853010\ttotal: 2.61s\tremaining: 1.87s\n",
      "233:\tlearn: 35285.6296278\ttotal: 2.62s\tremaining: 1.86s\n",
      "234:\tlearn: 35260.0459170\ttotal: 2.64s\tremaining: 1.85s\n",
      "235:\tlearn: 35236.6507449\ttotal: 2.65s\tremaining: 1.84s\n",
      "236:\tlearn: 35199.9981959\ttotal: 2.67s\tremaining: 1.83s\n",
      "237:\tlearn: 35110.1769278\ttotal: 2.68s\tremaining: 1.82s\n",
      "238:\tlearn: 35077.9246549\ttotal: 2.7s\tremaining: 1.82s\n",
      "239:\tlearn: 35037.1614959\ttotal: 2.71s\tremaining: 1.81s\n",
      "240:\tlearn: 35030.3351362\ttotal: 2.72s\tremaining: 1.8s\n",
      "241:\tlearn: 35028.3538848\ttotal: 2.74s\tremaining: 1.79s\n",
      "242:\tlearn: 34994.0576877\ttotal: 2.74s\tremaining: 1.77s\n",
      "243:\tlearn: 34986.2098186\ttotal: 2.76s\tremaining: 1.76s\n",
      "244:\tlearn: 34930.0439074\ttotal: 2.77s\tremaining: 1.75s\n",
      "245:\tlearn: 34897.3376611\ttotal: 2.77s\tremaining: 1.74s\n",
      "246:\tlearn: 34834.3438827\ttotal: 2.79s\tremaining: 1.73s\n",
      "247:\tlearn: 34813.5219840\ttotal: 2.8s\tremaining: 1.72s\n",
      "248:\tlearn: 34812.6301171\ttotal: 2.81s\tremaining: 1.7s\n",
      "249:\tlearn: 34716.1063515\ttotal: 2.82s\tremaining: 1.69s\n",
      "250:\tlearn: 34707.4390151\ttotal: 2.84s\tremaining: 1.68s\n",
      "251:\tlearn: 34628.5540627\ttotal: 2.85s\tremaining: 1.68s\n",
      "252:\tlearn: 34611.9887001\ttotal: 2.87s\tremaining: 1.67s\n",
      "253:\tlearn: 34589.4251948\ttotal: 2.88s\tremaining: 1.66s\n",
      "254:\tlearn: 34576.1163769\ttotal: 2.9s\tremaining: 1.65s\n",
      "255:\tlearn: 34513.5199337\ttotal: 2.92s\tremaining: 1.64s\n",
      "256:\tlearn: 34479.7319149\ttotal: 2.94s\tremaining: 1.63s\n",
      "257:\tlearn: 34466.6534236\ttotal: 2.95s\tremaining: 1.63s\n",
      "258:\tlearn: 34450.0556438\ttotal: 2.97s\tremaining: 1.61s\n",
      "259:\tlearn: 34410.3433623\ttotal: 2.98s\tremaining: 1.61s\n",
      "260:\tlearn: 34370.0665535\ttotal: 3s\tremaining: 1.6s\n",
      "261:\tlearn: 34368.7198249\ttotal: 3.02s\tremaining: 1.59s\n",
      "262:\tlearn: 34326.7044233\ttotal: 3.04s\tremaining: 1.58s\n",
      "263:\tlearn: 34269.6313776\ttotal: 3.06s\tremaining: 1.57s\n",
      "264:\tlearn: 34264.8115019\ttotal: 3.07s\tremaining: 1.56s\n",
      "265:\tlearn: 34234.7763118\ttotal: 3.09s\tremaining: 1.55s\n",
      "266:\tlearn: 34216.8150667\ttotal: 3.1s\tremaining: 1.55s\n",
      "267:\tlearn: 34185.3354083\ttotal: 3.12s\tremaining: 1.54s\n",
      "268:\tlearn: 34150.5684376\ttotal: 3.14s\tremaining: 1.53s\n",
      "269:\tlearn: 34107.0206726\ttotal: 3.15s\tremaining: 1.52s\n",
      "270:\tlearn: 34106.5576244\ttotal: 3.17s\tremaining: 1.51s\n",
      "271:\tlearn: 34105.2301887\ttotal: 3.18s\tremaining: 1.5s\n",
      "272:\tlearn: 34058.6372876\ttotal: 3.2s\tremaining: 1.49s\n",
      "273:\tlearn: 34041.0162682\ttotal: 3.22s\tremaining: 1.48s\n",
      "274:\tlearn: 34031.4989623\ttotal: 3.23s\tremaining: 1.47s\n",
      "275:\tlearn: 34013.2263032\ttotal: 3.25s\tremaining: 1.46s\n",
      "276:\tlearn: 33996.7622699\ttotal: 3.27s\tremaining: 1.45s\n",
      "277:\tlearn: 33990.8284084\ttotal: 3.29s\tremaining: 1.44s\n",
      "278:\tlearn: 33974.8392881\ttotal: 3.31s\tremaining: 1.44s\n",
      "279:\tlearn: 33951.8798522\ttotal: 3.33s\tremaining: 1.43s\n",
      "280:\tlearn: 33936.3636192\ttotal: 3.35s\tremaining: 1.42s\n",
      "281:\tlearn: 33859.3676828\ttotal: 3.36s\tremaining: 1.41s\n",
      "282:\tlearn: 33802.3467892\ttotal: 3.38s\tremaining: 1.4s\n",
      "283:\tlearn: 33796.2557490\ttotal: 3.39s\tremaining: 1.39s\n",
      "284:\tlearn: 33789.3634643\ttotal: 3.41s\tremaining: 1.38s\n",
      "285:\tlearn: 33649.7781334\ttotal: 3.43s\tremaining: 1.37s\n",
      "286:\tlearn: 33646.0503362\ttotal: 3.44s\tremaining: 1.35s\n",
      "287:\tlearn: 33640.7227249\ttotal: 3.46s\tremaining: 1.35s\n",
      "288:\tlearn: 33634.8435405\ttotal: 3.48s\tremaining: 1.33s\n",
      "289:\tlearn: 33633.5754944\ttotal: 3.49s\tremaining: 1.32s\n",
      "290:\tlearn: 33621.8761714\ttotal: 3.5s\tremaining: 1.31s\n",
      "291:\tlearn: 33591.3321049\ttotal: 3.51s\tremaining: 1.3s\n",
      "292:\tlearn: 33517.9228292\ttotal: 3.52s\tremaining: 1.29s\n",
      "293:\tlearn: 33464.0213459\ttotal: 3.54s\tremaining: 1.27s\n",
      "294:\tlearn: 33440.5174470\ttotal: 3.54s\tremaining: 1.26s\n",
      "295:\tlearn: 33435.4085600\ttotal: 3.55s\tremaining: 1.25s\n",
      "296:\tlearn: 33434.9397459\ttotal: 3.56s\tremaining: 1.23s\n",
      "297:\tlearn: 33399.1344295\ttotal: 3.57s\tremaining: 1.22s\n",
      "298:\tlearn: 33391.0431278\ttotal: 3.58s\tremaining: 1.21s\n",
      "299:\tlearn: 33360.9234501\ttotal: 3.59s\tremaining: 1.2s\n",
      "300:\tlearn: 33359.0868437\ttotal: 3.6s\tremaining: 1.19s\n",
      "301:\tlearn: 33352.3844549\ttotal: 3.61s\tremaining: 1.17s\n",
      "302:\tlearn: 33338.8939606\ttotal: 3.62s\tremaining: 1.16s\n",
      "303:\tlearn: 33338.0931407\ttotal: 3.63s\tremaining: 1.15s\n",
      "304:\tlearn: 33279.6061439\ttotal: 3.64s\tremaining: 1.13s\n",
      "305:\tlearn: 33238.1891765\ttotal: 3.65s\tremaining: 1.12s\n",
      "306:\tlearn: 33231.9392015\ttotal: 3.66s\tremaining: 1.11s\n",
      "307:\tlearn: 33216.1450725\ttotal: 3.67s\tremaining: 1.1s\n",
      "308:\tlearn: 33211.8541762\ttotal: 3.69s\tremaining: 1.09s\n",
      "309:\tlearn: 33153.3613684\ttotal: 3.7s\tremaining: 1.07s\n",
      "310:\tlearn: 33140.7875833\ttotal: 3.71s\tremaining: 1.06s\n",
      "311:\tlearn: 33048.2663563\ttotal: 3.73s\tremaining: 1.05s\n",
      "312:\tlearn: 33031.6070750\ttotal: 3.74s\tremaining: 1.04s\n",
      "313:\tlearn: 33010.8008515\ttotal: 3.75s\tremaining: 1.03s\n",
      "314:\tlearn: 32966.7488617\ttotal: 3.75s\tremaining: 1.01s\n",
      "315:\tlearn: 32966.1816843\ttotal: 3.76s\tremaining: 1s\n",
      "316:\tlearn: 32962.4818734\ttotal: 3.77s\tremaining: 987ms\n",
      "317:\tlearn: 32930.6807311\ttotal: 3.78s\tremaining: 974ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318:\tlearn: 32923.2662552\ttotal: 3.79s\tremaining: 961ms\n",
      "319:\tlearn: 32917.1286797\ttotal: 3.79s\tremaining: 949ms\n",
      "320:\tlearn: 32884.3884600\ttotal: 3.8s\tremaining: 935ms\n",
      "321:\tlearn: 32874.0570320\ttotal: 3.81s\tremaining: 922ms\n",
      "322:\tlearn: 32860.9869368\ttotal: 3.81s\tremaining: 909ms\n",
      "323:\tlearn: 32793.2893913\ttotal: 3.82s\tremaining: 896ms\n",
      "324:\tlearn: 32790.0080991\ttotal: 3.83s\tremaining: 883ms\n",
      "325:\tlearn: 32786.6077641\ttotal: 3.83s\tremaining: 870ms\n",
      "326:\tlearn: 32782.6943414\ttotal: 3.84s\tremaining: 857ms\n",
      "327:\tlearn: 32727.7775562\ttotal: 3.85s\tremaining: 844ms\n",
      "328:\tlearn: 32725.1854958\ttotal: 3.85s\tremaining: 832ms\n",
      "329:\tlearn: 32708.4919192\ttotal: 3.86s\tremaining: 819ms\n",
      "330:\tlearn: 32705.0870372\ttotal: 3.87s\tremaining: 806ms\n",
      "331:\tlearn: 32651.1788206\ttotal: 3.87s\tremaining: 793ms\n",
      "332:\tlearn: 32646.8757478\ttotal: 3.88s\tremaining: 781ms\n",
      "333:\tlearn: 32635.8551469\ttotal: 3.88s\tremaining: 768ms\n",
      "334:\tlearn: 32631.1582433\ttotal: 3.89s\tremaining: 755ms\n",
      "335:\tlearn: 32620.4754699\ttotal: 3.9s\tremaining: 743ms\n",
      "336:\tlearn: 32595.4782725\ttotal: 3.9s\tremaining: 730ms\n",
      "337:\tlearn: 32591.1862933\ttotal: 3.91s\tremaining: 718ms\n",
      "338:\tlearn: 32589.9861509\ttotal: 3.92s\tremaining: 705ms\n",
      "339:\tlearn: 32586.7825765\ttotal: 3.93s\tremaining: 693ms\n",
      "340:\tlearn: 32567.3725420\ttotal: 3.93s\tremaining: 680ms\n",
      "341:\tlearn: 32506.4590600\ttotal: 3.94s\tremaining: 668ms\n",
      "342:\tlearn: 32493.9297645\ttotal: 3.95s\tremaining: 656ms\n",
      "343:\tlearn: 32491.9610773\ttotal: 3.95s\tremaining: 644ms\n",
      "344:\tlearn: 32489.4129566\ttotal: 3.96s\tremaining: 632ms\n",
      "345:\tlearn: 32489.2053839\ttotal: 3.97s\tremaining: 620ms\n",
      "346:\tlearn: 32482.0787650\ttotal: 3.98s\tremaining: 608ms\n",
      "347:\tlearn: 32481.1825425\ttotal: 4s\tremaining: 597ms\n",
      "348:\tlearn: 32444.3542086\ttotal: 4s\tremaining: 585ms\n",
      "349:\tlearn: 32392.4824903\ttotal: 4.01s\tremaining: 573ms\n",
      "350:\tlearn: 32333.9743774\ttotal: 4.03s\tremaining: 562ms\n",
      "351:\tlearn: 32331.0800703\ttotal: 4.04s\tremaining: 551ms\n",
      "352:\tlearn: 32328.3224822\ttotal: 4.05s\tremaining: 539ms\n",
      "353:\tlearn: 32323.6312282\ttotal: 4.06s\tremaining: 527ms\n",
      "354:\tlearn: 32306.3467484\ttotal: 4.07s\tremaining: 515ms\n",
      "355:\tlearn: 32304.2448462\ttotal: 4.08s\tremaining: 504ms\n",
      "356:\tlearn: 32281.0880782\ttotal: 4.09s\tremaining: 493ms\n",
      "357:\tlearn: 32275.9267376\ttotal: 4.1s\tremaining: 481ms\n",
      "358:\tlearn: 32255.5803548\ttotal: 4.11s\tremaining: 469ms\n",
      "359:\tlearn: 32255.0421919\ttotal: 4.12s\tremaining: 458ms\n",
      "360:\tlearn: 32241.0076371\ttotal: 4.13s\tremaining: 446ms\n",
      "361:\tlearn: 32218.3190615\ttotal: 4.14s\tremaining: 435ms\n",
      "362:\tlearn: 32211.0136085\ttotal: 4.15s\tremaining: 423ms\n",
      "363:\tlearn: 32207.2159304\ttotal: 4.16s\tremaining: 412ms\n",
      "364:\tlearn: 32169.6783328\ttotal: 4.17s\tremaining: 400ms\n",
      "365:\tlearn: 32167.2523430\ttotal: 4.19s\tremaining: 389ms\n",
      "366:\tlearn: 32165.1496477\ttotal: 4.2s\tremaining: 378ms\n",
      "367:\tlearn: 32154.0772695\ttotal: 4.21s\tremaining: 366ms\n",
      "368:\tlearn: 32153.0714327\ttotal: 4.23s\tremaining: 355ms\n",
      "369:\tlearn: 32119.5934198\ttotal: 4.24s\tremaining: 344ms\n",
      "370:\tlearn: 32116.3100793\ttotal: 4.26s\tremaining: 333ms\n",
      "371:\tlearn: 32081.6874060\ttotal: 4.26s\tremaining: 321ms\n",
      "372:\tlearn: 32047.1754643\ttotal: 4.27s\tremaining: 309ms\n",
      "373:\tlearn: 32037.8761030\ttotal: 4.28s\tremaining: 297ms\n",
      "374:\tlearn: 32027.4766576\ttotal: 4.29s\tremaining: 286ms\n",
      "375:\tlearn: 32017.3751588\ttotal: 4.29s\tremaining: 274ms\n",
      "376:\tlearn: 32017.0150818\ttotal: 4.3s\tremaining: 262ms\n",
      "377:\tlearn: 31997.0041498\ttotal: 4.31s\tremaining: 251ms\n",
      "378:\tlearn: 31993.4012842\ttotal: 4.31s\tremaining: 239ms\n",
      "379:\tlearn: 31984.4348743\ttotal: 4.32s\tremaining: 227ms\n",
      "380:\tlearn: 31941.0818733\ttotal: 4.33s\tremaining: 216ms\n",
      "381:\tlearn: 31858.7478600\ttotal: 4.33s\tremaining: 204ms\n",
      "382:\tlearn: 31851.7311254\ttotal: 4.34s\tremaining: 193ms\n",
      "383:\tlearn: 31838.5415051\ttotal: 4.35s\tremaining: 181ms\n",
      "384:\tlearn: 31818.9287492\ttotal: 4.35s\tremaining: 170ms\n",
      "385:\tlearn: 31805.3233742\ttotal: 4.36s\tremaining: 158ms\n",
      "386:\tlearn: 31779.3816978\ttotal: 4.37s\tremaining: 147ms\n",
      "387:\tlearn: 31778.4765457\ttotal: 4.37s\tremaining: 135ms\n",
      "388:\tlearn: 31745.0586636\ttotal: 4.38s\tremaining: 124ms\n",
      "389:\tlearn: 31744.9744907\ttotal: 4.4s\tremaining: 113ms\n",
      "390:\tlearn: 31730.1286222\ttotal: 4.41s\tremaining: 102ms\n",
      "391:\tlearn: 31648.9664696\ttotal: 4.42s\tremaining: 90.3ms\n",
      "392:\tlearn: 31629.0395855\ttotal: 4.44s\tremaining: 79ms\n",
      "393:\tlearn: 31621.5695237\ttotal: 4.44s\tremaining: 67.7ms\n",
      "394:\tlearn: 31602.2247813\ttotal: 4.45s\tremaining: 56.3ms\n",
      "395:\tlearn: 31601.6524520\ttotal: 4.46s\tremaining: 45ms\n",
      "396:\tlearn: 31598.4290680\ttotal: 4.46s\tremaining: 33.7ms\n",
      "397:\tlearn: 31596.3397905\ttotal: 4.47s\tremaining: 22.5ms\n",
      "398:\tlearn: 31579.3726226\ttotal: 4.48s\tremaining: 11.2ms\n",
      "399:\tlearn: 31556.6983458\ttotal: 4.48s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1a1dd84e80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE: 995825210.4877136\n",
      "val MSE: 782900887.313009\n"
     ]
    }
   ],
   "source": [
    "catboost_pred = catboost.predict(X_train)\n",
    "print('train MSE:', mean_squared_error(catboost_pred, y_train))\n",
    "catboost_pred = catboost.predict(X_val)\n",
    "print('val MSE:', mean_squared_error(catboost_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7277480507165875\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(catboost_pred, y_val) / mean_squared_error(rf_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data (k, X):\n",
    "    n = X.shape[0] \n",
    "    split_X = [X[(n//k)*i : (n//k)*(i+1)] for i in range (0, k-n%k)]\n",
    "    a = (k-n%k) * (n//k)\n",
    "    for i in range (0, n%k):\n",
    "        split_X.append(X[a+i*(n-a)//(n%k): a+(i+1)*(n-a)//(n%k)])\n",
    "    return split_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove(List,i):\n",
    "    return List[:i] + List[i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 2]]), array([[2, 3],\n",
       "        [3, 4]])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,2],[2,3],[3,4]])\n",
    "split_data (2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_pred (predictions_ensemble, y_true, metric=mean_squared_error, less_better=True):\n",
    "    weighted_prediction = np.zeros(len(y_val))\n",
    "    prediction_metric = []\n",
    "    if less_better:\n",
    "        for prediction in predictions_ensemble:\n",
    "            prediction_metric.append(1 / metric(prediction, y_true))\n",
    "            weighted_prediction += np.array(prediction) * prediction_metric[-1]\n",
    "    else:\n",
    "        for prediction in predictions_ensemble:\n",
    "            prediction_metric.append(metric(prediction, y_true))\n",
    "            weighted_prediction += np.array(prediction) * prediction_metric[-1]\n",
    "    return weighted_prediction / sum(prediction_metric), np.array(prediction_metric) / sum(prediction_metric)\n",
    "\n",
    "def MyEnsemble_predict (Ensemble, X_val, y_val,metric=mean_squared_error, less_better=True):\n",
    "    predictions_ensemble = []\n",
    "    for i, boost in enumerate(Ensemble):\n",
    "        predictions_ensemble.append(boost.predict (X_val))\n",
    "    return weighted_pred(predictions_ensemble, y_val, metric=metric, less_better=less_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_weights (FINAL_STACK, y, metric=mean_squared_error, less_better=True, step=0.001,iterations=500):\n",
    "    weights = np.array([1/len(FINAL_STACK) for i in range (len(FINAL_STACK))])\n",
    "    result =  metric (y, np.array(FINAL_STACK).T.dot(weights)) \n",
    "    sum_koef = sum(weights)\n",
    "    for i in range (iterations):\n",
    "        for j in range (len(FINAL_STACK)):\n",
    "            weights[j] += step\n",
    "            iter_res_p = metric (y, np.array(FINAL_STACK).T.dot(weights) / (sum_koef + step))\n",
    "            if (iter_res_p > result and less_better==True) or (iter_res_p < result and less_better==False):\n",
    "                weights[j] -= 2 * step\n",
    "                iter_res_n = metric (y, np.array(FINAL_STACK).T.dot(np.array(weights)) / (sum_koef - step))\n",
    "                if (iter_res_n < result and less_better==True) or (iter_res_n > result and less_better==False):\n",
    "                    result = iter_res_n \n",
    "                    sum_koef -= step\n",
    "                else:\n",
    "                    weights[j] += step\n",
    "            else: \n",
    "                result = iter_res_p \n",
    "                sum_koef += step\n",
    "                \n",
    "    return np.array(FINAL_STACK).T.dot(weights) / sum_koef, weights / sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacking (MyEnsemble, n, X_train, X_test, y_train, fit=False): #n - number of folds\n",
    "    split_X = split_data (n, X_train)\n",
    "    split_y = split_data (n, y_train)\n",
    "    A_meta = []\n",
    "    T_meta = []\n",
    "    for model in MyEnsemble:\n",
    "        if fit == True:\n",
    "            model.fit(X_train, y_train)\n",
    "        T_meta.append(np.array(model.predict(X_test)))\n",
    "    for i in range (n):\n",
    "        X_pred = split_X[i]\n",
    "        X_iter = np.concatenate(remove(split_X, i))\n",
    "        y_iter = np.concatenate(remove(split_y, i))\n",
    "        A_meta_iter=[]\n",
    "        for model in MyEnsemble:\n",
    "            if fit == True:\n",
    "                model.fit(X_iter, y_iter)\n",
    "            A_meta_iter.append(np.array(model.predict(X_pred)))\n",
    "        A_meta_iter = np.vstack(A_meta_iter).T\n",
    "        A_meta.append(A_meta_iter)\n",
    "    A_meta = np.vstack(A_meta)\n",
    "    T_meta = np.vstack(T_meta).T\n",
    "    LR = LinearRegression(normalize=True)\n",
    "    LR.fit(A_meta, y_train)\n",
    "    return LR.predict(T_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MyEnsemble = [boost, rf_regressor, xgb_regressor, catboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "Stack_pred = stacking (MyEnsemble, 3, X_train, X_val, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6226769748169668\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(Stack_pred, y_val) / mean_squared_error(rf_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import explained_variance_score as EVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "final_prediction_1 = MyEnsemble_predict (MyEnsemble, X_val, y_val, metric=mean_squared_error)\n",
    "final_prediction_2 = MyEnsemble_predict (MyEnsemble, X_val, y_val, metric=MAE)\n",
    "final_prediction_3 = MyEnsemble_predict (MyEnsemble, X_val, y_val, metric=EVS, less_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FINAL_STACK = [Stack_pred, final_prediction_1[0], final_prediction_3[0], final_prediction_2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FINAL_PREDICT = find_weights(FINAL_STACK, y_val, metric=mean_squared_error, less_better=True, step=0.0001,iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08108108, 12.22245322, -9.40540541, -1.73596674])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_PREDICT[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526471934393903\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(FINAL_PREDICT[0], y_val) / mean_squared_error(rf_regressor_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/test.csv')\n",
    "test = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandrkagan/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3660: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "test_num = test.select_dtypes(include=['int', 'float'])\n",
    "X_test = np.array(test_num.fillna(test_num.mean(), inplace=True).drop(labels=['player_ID'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "Predictions = [model.predict(X_test) for model in MyEnsemble]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "Stack_pred_test = stacking (MyEnsemble, 3, X_train, X_test, y_train)\n",
    "test_answers1 = np.dot(final_prediction_1[1], Predictions)\n",
    "test_answers2 = np.dot(final_prediction_2[1], Predictions)\n",
    "test_answers3 = np.dot(final_prediction_3[1], Predictions)\n",
    "Final_answers = [Stack_pred_test, test_answers1, test_answers2, test_answers3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_prediction_test = np.dot(FINAL_PREDICT[1], Final_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat((test['player_ID'], pd.Series(final_prediction_test )), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./data/test_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_submission = pd.read_csv('./data/test_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_ID</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9991</td>\n",
       "      <td>-8033.111034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13037</td>\n",
       "      <td>-10852.444449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1254</td>\n",
       "      <td>-7540.611491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19697</td>\n",
       "      <td>-11382.711132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12390</td>\n",
       "      <td>-11031.735527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_ID             0\n",
       "0       9991  -8033.111034\n",
       "1      13037 -10852.444449\n",
       "2       1254  -7540.611491\n",
       "3      19697 -11382.711132\n",
       "4      12390 -11031.735527"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_submission = pd.read_csv('./data/test_submission.csv')\n",
    "true_submssion = pd.read_csv('./data/test_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert sum(my_submission['player_ID'].values != true_submssion['player_ID'].values) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(my_submission['player_ID'], true_submssion['player_ID'])\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
